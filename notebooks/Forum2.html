
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Forum 2 - From Metadata to Insights &#8212; My Jupyter Book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=35598371" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/Forum2';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="Forum 2 - From Metadata to Insights" href="../tutorials/forum2-overview.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
  
    <p class="title logo__title">My Jupyter Book</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    SSP Data Forums: Building a Connected, Data-Capable SBES Community
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Details</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../details/ssp-overview.html">üåê SSP Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../details/organizing-team.html">Organizing Team</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Preparation &amp; Technical Details</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../prep/who-should-attend.html">üéì Who Should Attend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../prep/what-to-expect.html">üìÖ What to Expect</a></li>
<li class="toctree-l1"><a class="reference internal" href="../prep/what-to-bring.html">üß© What to Keep in Mind</a></li>
<li class="toctree-l1"><a class="reference internal" href="../prep/technical-notes.html">‚öôÔ∏è Technical Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../prep/additional-resources.html">üìö Additional Resources</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Forum Resources</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../tutorials/forum1-overview.html">Forum 1</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/forum2-overview.html">Forum 2</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Forum 2 Notebook (Downloadable)</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/notebooks/Forum2.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Forum 2 - From Metadata to Insights</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#goals-of-the-notebook">Goals of the notebook:</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-steps-we-will-follow">The Steps We Will Follow</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stop-think-about-your-own-data">Stop!  Think About Your Own Data</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#respond-in-the-chat"><strong>&gt;&gt;Respond in the chat&lt;&lt;</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#before-we-get-started-workplace-setup-imports">Before We Get Started - Workplace Setup (Imports)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1-use-an-api-to-explore-a-repository-view-metadata-and-download-data">Step 1: Use an API to explore a repository, view metadata, and download data</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simple-search-for-10-results">Simple search for 10 results</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transform-the-json-results">Transform the JSON results</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#search-for-more-than-10-results">Search for more than 10 results</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#subsetting-our-results">Subsetting Our Results</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1a-get-dataset-metadata-and-files">Step 1a: Get Dataset Metadata and Files</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#getting-metadata-for-a-single-dataset">Getting metadata for a single dataset</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#file-level-metadata">File level metadata</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#full-dataset-metadata">Full dataset metadata</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1b-download-a-file">Step 1b: Download a File</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#examine-the-dataset">Examine the dataset</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#variable-names">Variable names</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id1"><strong>&gt;&gt;Respond in the chat&lt;&lt;</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#unfortunately-nws-region-only-has-four-regions-nonetheless-it-might-be-useful-for-a-different-research-question">Unfortunately, ‚Äúnws_region‚Äù only has four regions.  Nonetheless, it might be useful for a different research question.</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-2-use-an-api-to-download-weather-data">Step 2: Use an API to download weather data</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#iowa-mesonet-api-do-not-run-at-this-time">Iowa Mesonet API - DO NOT RUN AT THIS TIME</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-3-joining-the-survey-data-with-weather-alerts">Step 3 - Joining the Survey Data with Weather Alerts</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#if-you-ran-the-api-call-in-step-2-you-should-skip-the-next-two-cells">If you ran the API call in Step 2, you should skip the next two cells.</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#if-you-ran-the-api-call-in-step-2-you-can-resume-here">If you ran the API call in Step 2, you can resume here.</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-3a-exporting-the-data-for-use-outside-jupyter">Step 3a: Exporting the Data for Use Outside Jupyter</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-4-exploring-the-combined-dataset">Step 4: Exploring the Combined Dataset</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#step-4a-quick-visualizations">Step 4a: Quick visualizations</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-4b-visualizing-wwwas-by-survey-reponses">Step 4b: Visualizing WWWAs by Survey Reponses</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-4c-quick-statistical-analyses">Step 4C: Quick Statistical Analyses</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#chi-square">1. Chi-Square</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#logistic-regression">2. Logistic Regression</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ordinal-logistic-regression">3. Ordinal Logistic Regression</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-bit-more-involved-did-wwas-really-affect-risk-perception">A Bit More Involved - Did WWAs <em>Really</em> Affect Risk Perception?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-possible-interpretation">A possible interpretation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#wrapping-up">Wrapping Up</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#moving-forward">Moving Forward</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="forum-2-from-metadata-to-insights">
<h1>Forum 2 - From Metadata to Insights<a class="headerlink" href="#forum-2-from-metadata-to-insights" title="Link to this heading">#</a></h1>
<p>Author: Jonathon Mote, PhD - Weather Program Office
September 2025</p>
<p>This tutorial is designed for social scientists who want to explore how their own data might begin to interface with weather and hazard datasets.  The tutorial will provide a quick overview of Jupyter notebooks and tools, some geospatial tools, and the use of APIs to access data.</p>
<section id="goals-of-the-notebook">
<h2>Goals of the notebook:<a class="headerlink" href="#goals-of-the-notebook" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p><strong>Work with APIs</strong> to search for, access, and download data programmatically</p></li>
<li><p>Organize, explore, and download datasets interactively using python libraries like <strong>pandas</strong> and <strong>requests</strong>.</p></li>
<li><p>Merge survey data with external data from the <strong>Iowa Environmental Mesonet</strong></p></li>
<li><p>Apply <strong>geospatial tools</strong> to handle location-based data</p></li>
<li><p>Create clear, reproducible <strong>visualizations</strong> and <strong>statistical analyses</strong> directly alongside your analysis</p></li>
<li><p>Document our process in a way that combines code, results, and explanation all in one place</p></li>
</ol>
<p>Note: Ensure that the datasets are open access, or you have an <strong>API key</strong> for restricted access.  An API key is a unique code generated by the data provider that allows users to authenticate and access the data.  For this tutorial, the datasets in this notebook do not require an API key.</p>
</section>
<section id="the-steps-we-will-follow">
<h2>The Steps We Will Follow<a class="headerlink" href="#the-steps-we-will-follow" title="Link to this heading">#</a></h2>
<div style="display:flex; flex-direction:column; align-items:center; gap:14px; margin:14px 0 6px 0;">
  <!-- Step 1 -->
  <div style="width:100%; max-width:900px; height:120px; background:#d0eff8; color:#ffffff; border-radius:12px;
              display:flex; align-items:center; justify-content:center; text-align:center;
              padding:0 20px; box-sizing:border-box; font-weight:700; line-height:1.3; font-size:20px;">
    Step 1: Use an API to explore a repository, view metadata, and "pull" social data
  </div>
  <div style="width:2px; height:28px; background:#bfbfbf; border-radius:1px;"></div>
  <!-- Step 2 -->
  <div style="width:100%; max-width:900px; height:120px; background:#0069af; color:#ffffff; border-radius:12px;
              display:flex; align-items:center; justify-content:center; text-align:center;
              padding:0 20px; box-sizing:border-box; font-weight:700; line-height:1.3; font-size:20px;">
    Step 2: Use an API to "pull" weather data
  </div>
  <div style="width:2px; height:28px; background:#bfbfbf; border-radius:1px;"></div>
  <!-- Step 3 -->
  <div style="width:100%; max-width:900px; height:120px; background:#004b98; color:#ffffff; border-radius:12px;
              display:flex; align-items:center; justify-content:center; text-align:center;
              padding:0 20px; box-sizing:border-box; font-weight:700; line-height:1.3; font-size:20px;">
    Step 3: Merge weather data and social data
  </div>
  <div style="width:2px; height:28px; background:#bfbfbf; border-radius:1px;"></div>
  <!-- Step 4 -->
  <div style="width:100%; max-width:900px; height:120px; background:#003087; color:#ffffff; border-radius:12px;
              display:flex; align-items:center; justify-content:center; text-align:center;
              padding:0 20px; box-sizing:border-box; font-weight:700; line-height:1.3; font-size:20px;">
    Step 4: Visualize and analyze the combined dataset
  </div>
</div>
</section>
<section id="stop-think-about-your-own-data">
<h2>Stop!  Think About Your Own Data<a class="headerlink" href="#stop-think-about-your-own-data" title="Link to this heading">#</a></h2>
<p>Thinking about your data, what types of weather-related data might bring additional insights?  What are some questions that you‚Äôre interested in?</p>
<section id="respond-in-the-chat">
<h3><strong>&gt;&gt;Respond in the chat&lt;&lt;</strong><a class="headerlink" href="#respond-in-the-chat" title="Link to this heading">#</a></h3>
<h2><span style="color:red">Our Research Question Today</span></h2>
<p>For the purposes of this tutorial, we will explore the following question: does exposure to watches, warnings, and advisories have an impact on survey responses to weather risk perception.  Specifically, we will focus on flood warnings, watches, and advisories.</p>
</section>
<section id="before-we-get-started-workplace-setup-imports">
<h3>Before We Get Started - Workplace Setup (Imports)<a class="headerlink" href="#before-we-get-started-workplace-setup-imports" title="Link to this heading">#</a></h3>
<p>In Jupyter, there are a large number of python-based ‚Äúlibraries‚Äù or ‚Äúpackages‚Äù that help with data loading, transformation, and analysis.  These libraries provide tools that help us do things like make graphs, work with data, or do more complex calculations, like regression.  It‚Äôs good practice to have all libraries imported at the beginning.  You can always add (even install) libraries as you go along, you just have to rerun the cells (or restart the <em>kernel</em> if a new install).</p>
<p>To run a cell, you can go to <strong>‚ÄúRun‚Äù</strong> in the Jupyter menu and select <strong>‚ÄúRun selected cell‚Äù</strong>.  However, it is easier to click on the chevron (‚ñ∂Ô∏è) in the editing menu.  There are also keyboard shortcuts like <strong>Shift+Enter</strong> or <strong>Ctrl+Enter</strong>.</p>
<p>In this tutorial, the primary libraries we will use are:</p>
<p><em>Data Handling</em></p>
<ul class="simple">
<li><p><strong>pandas</strong>: For working with tabular data in DataFrames.  It is commonly imported with an alias (pd), so we don‚Äôt constantly have to type out pandas.</p></li>
<li><p><strong>requests</strong>: For easily fetching data from web APIs and URLs (using GET, POST, etc).</p></li>
<li><p><strong>timedelta</strong>: Imported from the datetime library, for representing time intervals.</p></li>
<li><p><strong>BytesIO</strong>: Imported from the IO library, for treating in-memory bytes like a file for reading.</p></li>
<li><p><strong>ast</strong>: A python module which can be used for evaluating strings.</p></li>
</ul>
<p><em>Geospatial</em></p>
<ul class="simple">
<li><p><strong>geopandas</strong>: To work with geospatial data, allowing us to perform spatial operations and handle geometries such as points, polygons, and lines.</p></li>
<li><p><strong>Point</strong>: Imported from Shapely, for creating geometric points for mapping.</p></li>
</ul>
<p><em>Visualization</em></p>
<ul class="simple">
<li><p><strong>Pyplot</strong>: Imported from MatPlotLib using the alias ‚Äúplt‚Äù, for making simple customizable  plots and charts.</p></li>
<li><p><strong>Seaborn</strong>: Imported using the alias ‚Äúsns‚Äù, for making better looking visualizations.</p></li>
</ul>
<p><em>Utilities</em></p>
<ul class="simple">
<li><p><strong>time</strong>: Provides functions for working with time, such as measuring durations, pausing executions, and accessing system time.</p></li>
<li><p><strong>tqdm</strong>: Adds progress bars to loops for tracking execution.</p></li>
</ul>
<p><em>Statistical Modeling/Inference</em></p>
<ul class="simple">
<li><p><strong>scipy.stats.chi2_contingency</strong>: Imported from Scipy, to run a chi-square test of independence to check if two categorical variables are related.</p></li>
<li><p><strong>statsmodels.api as sm</strong>: Imported with the alias ‚Äúsm‚Äù, it provides tools for statistical models, including logistic regression.</p></li>
<li><p><strong>OrderedModel</strong>: Imported from statsmodels, used for ordinal logistic regression models when outcomes are ordered categories.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#import libraries</span>

<span class="c1"># data handling</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">requests</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datetime</span><span class="w"> </span><span class="kn">import</span> <span class="n">timedelta</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">io</span><span class="w"> </span><span class="kn">import</span> <span class="n">BytesIO</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections</span><span class="w"> </span><span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">ast</span>

<span class="c1"># geospatial</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">geopandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">gpd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">shapely.geometry</span><span class="w"> </span><span class="kn">import</span> <span class="n">Point</span>

<span class="c1">#visualization</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>

<span class="c1">#utilities</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tqdm</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>

<span class="c1">#statistical modeling/inference</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">chi2_contingency</span>        
<span class="kn">import</span><span class="w"> </span><span class="nn">statsmodels.api</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sm</span>                    
<span class="kn">from</span><span class="w"> </span><span class="nn">statsmodels.miscmodels.ordinal_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">OrderedModel</span> 
</pre></div>
</div>
</div>
</div>
<div style="background-color:#0085ca66; color:white; padding:20px; border-radius:10px; text-align:center; font-size:28px; font-weight:bold;">
  Step 1
</div>
</section>
</section>
<section id="step-1-use-an-api-to-explore-a-repository-view-metadata-and-download-data">
<h2>Step 1: Use an API to explore a repository, view metadata, and download data<a class="headerlink" href="#step-1-use-an-api-to-explore-a-repository-view-metadata-and-download-data" title="Link to this heading">#</a></h2>
<p>In this step, we will explore API access to a data repository, the Harvard Dataverse.  An API (Application Programming Interface) is just a set of rules and tools that allows different software to communicate and interact with each other.  In this case, we want our Jupyter notebook to interact with the server for information on datasets.  We use the python library ‚ÄúRequests‚Äù to simplify and automate our requests, and Dataverse returns what we requested (hopefully), typically in a format called JSON.  We then use Pandas to transform the JSON in a dataframe, making the results easier to read and manipulate.</p>
<ul class="simple">
<li><p><strong>Note</strong>: Not all APIs are created equally and there might be differences across repositories and data servers.  Check each API‚Äôs documentation for how to get started, authentication, search and data access, and more.  For Harvard‚Äôs Dataverse, the <a class="reference external" href="https://guides.dataverse.org/en/latest/api/index.html">Dataverse API Guide</a> is a comprehensive, up-to-date documentation for all operations in Harvard‚Äôs Dataverse.</p></li>
</ul>
<section id="simple-search-for-10-results">
<h3>Simple search for 10 results<a class="headerlink" href="#simple-search-for-10-results" title="Link to this heading">#</a></h3>
<p>By default, the Harvard Dataverse only returns 10 results per search request.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define search query</span>
<span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;ripberger&quot;</span>
<span class="n">search_url</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;https://dataverse.harvard.edu/api/search?q=</span><span class="si">{</span><span class="n">query</span><span class="si">}</span><span class="s2">&amp;type=dataset&quot;</span>

<span class="c1"># Perform search and show JSON</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">search_url</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
<span class="n">results</span>  <span class="c1"># Display raw JSON output</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;status&#39;: &#39;OK&#39;,
 &#39;data&#39;: {&#39;q&#39;: &#39;ripberger&#39;,
  &#39;total_count&#39;: 39,
  &#39;start&#39;: 0,
  &#39;spelling_alternatives&#39;: {},
  &#39;items&#39;: [{&#39;name&#39;: &#39;A comprehensive inventory and review of color in meteorological graphics&#39;,
    &#39;type&#39;: &#39;dataset&#39;,
    &#39;url&#39;: &#39;https://doi.org/10.7910/DVN/IFBAZ4&#39;,
    &#39;global_id&#39;: &#39;doi:10.7910/DVN/IFBAZ4&#39;,
    &#39;description&#39;: &#39;This dataset contains an inventory of colors used in 194 meteorological graphics produced by the U.S. National Centers for Environmental Prediction (NCEP). The graphics were collected between August 1, 2023, and November 9, 2023.&#39;,
    &#39;published_at&#39;: &#39;2025-04-22T13:26:32Z&#39;,
    &#39;publisher&#39;: &#39;Harvard Dataverse&#39;,
    &#39;citationHtml&#39;: &#39;Ripberger, Joseph; Bitterman, Abby; Rosen, Zoey, 2025, &quot;A comprehensive inventory and review of color in meteorological graphics&quot;, &lt;a href=&quot;https://doi.org/10.7910/DVN/IFBAZ4&quot; target=&quot;_blank&quot;&gt;https://doi.org/10.7910/DVN/IFBAZ4&lt;/a&gt;, Harvard Dataverse, V1, UNF:6:oGV2BM/aXuWgINpEP53sTQ== [fileUNF]&#39;,
    &#39;identifier_of_dataverse&#39;: &#39;harvard&#39;,
    &#39;name_of_dataverse&#39;: &#39;Harvard Dataverse&#39;,
    &#39;citation&#39;: &#39;Ripberger, Joseph; Bitterman, Abby; Rosen, Zoey, 2025, &quot;A comprehensive inventory and review of color in meteorological graphics&quot;, https://doi.org/10.7910/DVN/IFBAZ4, Harvard Dataverse, V1, UNF:6:oGV2BM/aXuWgINpEP53sTQ== [fileUNF]&#39;,
    &#39;publicationStatuses&#39;: [&#39;Published&#39;],
    &#39;storageIdentifier&#39;: &#39;s3://10.7910/DVN/IFBAZ4&#39;,
    &#39;subjects&#39;: [&#39;Earth and Environmental Sciences&#39;, &#39;Social Sciences&#39;],
    &#39;fileCount&#39;: 179,
    &#39;versionId&#39;: 441111,
    &#39;versionState&#39;: &#39;RELEASED&#39;,
    &#39;majorVersion&#39;: 1,
    &#39;minorVersion&#39;: 0,
    &#39;createdAt&#39;: &#39;2025-03-27T13:54:15Z&#39;,
    &#39;updatedAt&#39;: &#39;2025-04-22T13:26:32Z&#39;,
    &#39;contacts&#39;: [{&#39;name&#39;: &#39;Ripberger, Joseph&#39;,
      &#39;affiliation&#39;: &#39;University of Oklahoma&#39;}],
    &#39;publications&#39;: [{}],
    &#39;authors&#39;: [&#39;Ripberger, Joseph&#39;, &#39;Bitterman, Abby&#39;, &#39;Rosen, Zoey&#39;]},
   {&#39;name&#39;: &#39;S3OK Surveys&#39;,
    &#39;type&#39;: &#39;dataset&#39;,
    &#39;url&#39;: &#39;https://doi.org/10.7910/DVN/JHLMBU&#39;,
    &#39;image_url&#39;: &#39;https://dataverse.harvard.edu/api/datasets/12014083/logo&#39;,
    &#39;global_id&#39;: &#39;doi:10.7910/DVN/JHLMBU&#39;,
    &#39;description&#39;: &#39;This repository contains data and accompanying metadata (including survey instruments) from the S3OK component of the Oklahoma Meso-Scale Integrated Socio-Geographic Network (M-SISNet) survey. The S3OK project focused on developing socially sustainable solutions for water, carbon, and infrastructure resilience in Oklahoma. The survey was conducted in a panel format, with the same respondents surveyed across multiple waves over time. Additional data and metadata will be added to this repository as new waves are completed.&#39;,
    &#39;published_at&#39;: &#39;2025-08-29T11:02:55Z&#39;,
    &#39;publisher&#39;: &#39;The Oklahoma Meso-Scale Integrated Socio-Geographic Network (M-SISNet)&#39;,
    &#39;citationHtml&#39;: &#39;Ripberger, Joseph; Jenkins-Smith, Hank; Carlson, Nina; Henderson, Matt, 2025, &quot;S3OK Surveys&quot;, &lt;a href=&quot;https://doi.org/10.7910/DVN/JHLMBU&quot; target=&quot;_blank&quot;&gt;https://doi.org/10.7910/DVN/JHLMBU&lt;/a&gt;, Harvard Dataverse, V1, UNF:6:aBt+2AybCFwuYyOS5VpwyA== [fileUNF]&#39;,
    &#39;identifier_of_dataverse&#39;: &#39;msisnet&#39;,
    &#39;name_of_dataverse&#39;: &#39;The Oklahoma Meso-Scale Integrated Socio-Geographic Network (M-SISNet)&#39;,
    &#39;citation&#39;: &#39;Ripberger, Joseph; Jenkins-Smith, Hank; Carlson, Nina; Henderson, Matt, 2025, &quot;S3OK Surveys&quot;, https://doi.org/10.7910/DVN/JHLMBU, Harvard Dataverse, V1, UNF:6:aBt+2AybCFwuYyOS5VpwyA== [fileUNF]&#39;,
    &#39;publicationStatuses&#39;: [&#39;Published&#39;],
    &#39;storageIdentifier&#39;: &#39;s3://10.7910/DVN/JHLMBU&#39;,
    &#39;subjects&#39;: [&#39;Earth and Environmental Sciences&#39;,
     &#39;Engineering&#39;,
     &#39;Social Sciences&#39;,
     &#39;Agricultural Sciences&#39;],
    &#39;fileCount&#39;: 14,
    &#39;versionId&#39;: 501700,
    &#39;versionState&#39;: &#39;RELEASED&#39;,
    &#39;majorVersion&#39;: 1,
    &#39;minorVersion&#39;: 0,
    &#39;createdAt&#39;: &#39;2025-08-26T18:21:10Z&#39;,
    &#39;updatedAt&#39;: &#39;2025-08-29T11:02:55Z&#39;,
    &#39;contacts&#39;: [{&#39;name&#39;: &#39;Ripberger, Joseph&#39;,
      &#39;affiliation&#39;: &#39;University of Oklahoma&#39;}],
    &#39;publications&#39;: [{}],
    &#39;authors&#39;: [&#39;Ripberger, Joseph&#39;,
     &#39;Ripberger, Joseph&#39;,
     &#39;Jenkins-Smith, Hank&#39;,
     &#39;Jenkins-Smith, Hank&#39;,
     &#39;Carlson, Nina&#39;,
     &#39;Carlson, Nina&#39;,
     &#39;Henderson, Matt&#39;,
     &#39;Henderson, Matt&#39;]},
   {&#39;name&#39;: &#39;WX18&#39;,
    &#39;type&#39;: &#39;dataset&#39;,
    &#39;url&#39;: &#39;https://doi.org/10.7910/DVN/RHT4ON&#39;,
    &#39;image_url&#39;: &#39;https://dataverse.harvard.edu/api/datasets/3657707/logo&#39;,
    &#39;global_id&#39;: &#39;doi:10.7910/DVN/RHT4ON&#39;,
    &#39;description&#39;: &#39;The Severe Weather and Society Survey (WX) was designed and administered by the Center for Risk and Crisis Management (CRCM) at the University of Oklahoma. This is the second survey in the annual series (see Silva et al., 2017 for information on WX17). WX18 was fielded July 6-11, 2018 using an online questionnaire that was completed by 3,000 U.S. adults (age 18+) that were recruited from an Internet panel that matches the characteristics of the U.S. population as estimated in the U.S. Census. Following WX17, which was designed to establish baseline measures of the extent to which U.S. adults receive, understand, and respond to severe weather forecasts and warnings, WX18 was designed to continue and, in some cases, refine the measurement of these concepts. Additionally, WX18 measured public trust in the National Weather Service (NWS), extreme weather and climate risk perceptions, risk literacy, interpretations of probabilistic language, and response efficacy.&#39;,
    &#39;published_at&#39;: &#39;2020-02-03T22:11:23Z&#39;,
    &#39;publisher&#39;: &#39;Extreme Weather and Society Survey&#39;,
    &#39;citationHtml&#39;: &#39;Ripberger, Joseph; Silva, Carol; Jenkins-Smith, Hank; Krocak, Makenzie, 2020, &quot;WX18&quot;, &lt;a href=&quot;https://doi.org/10.7910/DVN/RHT4ON&quot; target=&quot;_blank&quot;&gt;https://doi.org/10.7910/DVN/RHT4ON&lt;/a&gt;, Harvard Dataverse, V1, UNF:6:Yyyznfcg+cNLP/7D2v9/wg== [fileUNF]&#39;,
    &#39;identifier_of_dataverse&#39;: &#39;wxsurvey&#39;,
    &#39;name_of_dataverse&#39;: &#39;Extreme Weather and Society Survey&#39;,
    &#39;citation&#39;: &#39;Ripberger, Joseph; Silva, Carol; Jenkins-Smith, Hank; Krocak, Makenzie, 2020, &quot;WX18&quot;, https://doi.org/10.7910/DVN/RHT4ON, Harvard Dataverse, V1, UNF:6:Yyyznfcg+cNLP/7D2v9/wg== [fileUNF]&#39;,
    &#39;publicationStatuses&#39;: [&#39;Published&#39;],
    &#39;storageIdentifier&#39;: &#39;s3://10.7910/DVN/RHT4ON&#39;,
    &#39;subjects&#39;: [&#39;Social Sciences&#39;],
    &#39;fileCount&#39;: 3,
    &#39;versionId&#39;: 210551,
    &#39;versionState&#39;: &#39;RELEASED&#39;,
    &#39;majorVersion&#39;: 1,
    &#39;minorVersion&#39;: 1,
    &#39;createdAt&#39;: &#39;2020-01-13T14:26:39Z&#39;,
    &#39;updatedAt&#39;: &#39;2020-09-01T14:43:00Z&#39;,
    &#39;contacts&#39;: [{&#39;name&#39;: &#39;Ripberger, Joseph&#39;,
      &#39;affiliation&#39;: &#39;University of Oklahoma&#39;}],
    &#39;publications&#39;: [{}],
    &#39;authors&#39;: [&#39;Ripberger, Joseph&#39;,
     &#39;Silva, Carol&#39;,
     &#39;Jenkins-Smith, Hank&#39;,
     &#39;Krocak, Makenzie&#39;]},
   {&#39;name&#39;: &#39;WX19&#39;,
    &#39;type&#39;: &#39;dataset&#39;,
    &#39;url&#39;: &#39;https://doi.org/10.7910/DVN/MLCJEW&#39;,
    &#39;image_url&#39;: &#39;https://dataverse.harvard.edu/api/datasets/3657722/logo&#39;,
    &#39;global_id&#39;: &#39;doi:10.7910/DVN/MLCJEW&#39;,
    &#39;description&#39;: &#39;The Severe Weather and Society Survey (WX) was designed and administered by the Center for Risk and Crisis Management (CRCM) at the University of Oklahoma. This is the third survey in the annual series (see Silva et al. 2017 and Silva et al. 2018 for information on WX17 and WX18). WX19 was fielded June 24 ‚Äì July 6, 2019 using an online questionnaire that was completed by 3,006 U.S. adults (age 18+) that were recruited from an Internet panel that matches the characteristics of the U.S. population as estimated in the U.S. Census. Following WX17 and WX18, which were designed to establish baseline measures of the extent to which U.S. adults receive, understand, and respond to severe weather forecasts and warnings, WX19 was designed to continue and, in some cases, refine the measurement of these concepts. Additionally, WX19 measured public trust in the National Weather Service (NWS), extreme weather and climate risk perceptions, risk literacy, interpretations of probabilistic language, and extreme weather preparedness.&#39;,
    &#39;published_at&#39;: &#39;2020-02-03T22:10:59Z&#39;,
    &#39;publisher&#39;: &#39;Extreme Weather and Society Survey&#39;,
    &#39;citationHtml&#39;: &#39;Ripberger, Joseph; Silva, Carol; Jenkins-Smith, Hank; Krocak, Makenzie, 2020, &quot;WX19&quot;, &lt;a href=&quot;https://doi.org/10.7910/DVN/MLCJEW&quot; target=&quot;_blank&quot;&gt;https://doi.org/10.7910/DVN/MLCJEW&lt;/a&gt;, Harvard Dataverse, V1, UNF:6:VuGLjhYyzRx0N28t1J/LHQ== [fileUNF]&#39;,
    &#39;identifier_of_dataverse&#39;: &#39;wxsurvey&#39;,
    &#39;name_of_dataverse&#39;: &#39;Extreme Weather and Society Survey&#39;,
    &#39;citation&#39;: &#39;Ripberger, Joseph; Silva, Carol; Jenkins-Smith, Hank; Krocak, Makenzie, 2020, &quot;WX19&quot;, https://doi.org/10.7910/DVN/MLCJEW, Harvard Dataverse, V1, UNF:6:VuGLjhYyzRx0N28t1J/LHQ== [fileUNF]&#39;,
    &#39;publicationStatuses&#39;: [&#39;Published&#39;],
    &#39;storageIdentifier&#39;: &#39;s3://10.7910/DVN/MLCJEW&#39;,
    &#39;subjects&#39;: [&#39;Social Sciences&#39;],
    &#39;fileCount&#39;: 3,
    &#39;versionId&#39;: 210552,
    &#39;versionState&#39;: &#39;RELEASED&#39;,
    &#39;majorVersion&#39;: 1,
    &#39;minorVersion&#39;: 1,
    &#39;createdAt&#39;: &#39;2020-01-13T14:28:14Z&#39;,
    &#39;updatedAt&#39;: &#39;2020-09-01T14:43:57Z&#39;,
    &#39;contacts&#39;: [{&#39;name&#39;: &#39;Ripberger, Joseph&#39;,
      &#39;affiliation&#39;: &#39;University of Oklahoma&#39;}],
    &#39;publications&#39;: [{}],
    &#39;authors&#39;: [&#39;Ripberger, Joseph&#39;,
     &#39;Silva, Carol&#39;,
     &#39;Jenkins-Smith, Hank&#39;,
     &#39;Krocak, Makenzie&#39;]},
   {&#39;name&#39;: &#39;WX17&#39;,
    &#39;type&#39;: &#39;dataset&#39;,
    &#39;url&#39;: &#39;https://doi.org/10.7910/DVN/GSTYK4&#39;,
    &#39;image_url&#39;: &#39;https://dataverse.harvard.edu/api/datasets/3674404/logo&#39;,
    &#39;global_id&#39;: &#39;doi:10.7910/DVN/GSTYK4&#39;,
    &#39;description&#39;: &#39;The Severe Weather and Society Survey (WX17) was designed and administered by the Center for Risk and Crisis Management (CRCM) at the University of Oklahoma. WX17 was fielded in June 2017 using an online questionnaire that was completed by 2,009 U.S. adults (age 18+) that were recruited from an Internet panel that matches the characteristics of the U.S. population as estimated in the U.S. Census. The survey was designed to establish baseline measures of the extent to which U.S. adults receive, understand, and respond to severe weather forecasts and warnings. Additionally, the survey measured public preferences about tradeoffs during the forecast process (e.g., lead time vs. accuracy/precision of warnings), trust in the National Weather Service (NWS), hazard risk literacy, the relative importance of probability and intensity in risk characterization, and the value of geographically specific and continuous severe weather warnings, such as those envisioned by the Forecasting a Continuum of Environmental Threats (FACETs) framework.&#39;,
    &#39;published_at&#39;: &#39;2020-02-03T22:10:34Z&#39;,
    &#39;publisher&#39;: &#39;Extreme Weather and Society Survey&#39;,
    &#39;citationHtml&#39;: &#39;Ripberger, Joseph; Silva, Carol; Jenkins-Smith, Hank; Krocak, Makenzie, 2020, &quot;WX17&quot;, &lt;a href=&quot;https://doi.org/10.7910/DVN/GSTYK4&quot; target=&quot;_blank&quot;&gt;https://doi.org/10.7910/DVN/GSTYK4&lt;/a&gt;, Harvard Dataverse, V1, UNF:6:x2+/QOuNR25/XiOkx3MzIg== [fileUNF]&#39;,
    &#39;identifier_of_dataverse&#39;: &#39;wxsurvey&#39;,
    &#39;name_of_dataverse&#39;: &#39;Extreme Weather and Society Survey&#39;,
    &#39;citation&#39;: &#39;Ripberger, Joseph; Silva, Carol; Jenkins-Smith, Hank; Krocak, Makenzie, 2020, &quot;WX17&quot;, https://doi.org/10.7910/DVN/GSTYK4, Harvard Dataverse, V1, UNF:6:x2+/QOuNR25/XiOkx3MzIg== [fileUNF]&#39;,
    &#39;publicationStatuses&#39;: [&#39;Published&#39;],
    &#39;storageIdentifier&#39;: &#39;s3://10.7910/DVN/GSTYK4&#39;,
    &#39;subjects&#39;: [&#39;Social Sciences&#39;],
    &#39;fileCount&#39;: 3,
    &#39;versionId&#39;: 210550,
    &#39;versionState&#39;: &#39;RELEASED&#39;,
    &#39;majorVersion&#39;: 1,
    &#39;minorVersion&#39;: 1,
    &#39;createdAt&#39;: &#39;2020-01-28T20:00:17Z&#39;,
    &#39;updatedAt&#39;: &#39;2020-09-01T14:41:58Z&#39;,
    &#39;contacts&#39;: [{&#39;name&#39;: &#39;Ripberger, Joseph&#39;,
      &#39;affiliation&#39;: &#39;University of Oklahoma&#39;}],
    &#39;publications&#39;: [{}],
    &#39;authors&#39;: [&#39;Ripberger, Joseph&#39;,
     &#39;Silva, Carol&#39;,
     &#39;Jenkins-Smith, Hank&#39;,
     &#39;Krocak, Makenzie&#39;]},
   {&#39;name&#39;: &#39;WX20&#39;,
    &#39;type&#39;: &#39;dataset&#39;,
    &#39;url&#39;: &#39;https://doi.org/10.7910/DVN/EWOCUA&#39;,
    &#39;image_url&#39;: &#39;https://dataverse.harvard.edu/api/datasets/4004497/logo&#39;,
    &#39;global_id&#39;: &#39;doi:10.7910/DVN/EWOCUA&#39;,
    &#39;description&#39;: &#39;The Severe Weather and Society Survey (WX) was designed and administered by the Center for Risk and Crisis Management (CRCM) at the University of Oklahoma. This is the fourth survey in the annual series (see Silva et al. 2017, Silva et al. 2018, and Krocak et al. 2019 for information on WX17, WX18, and WX19). WX20 was fielded June 10 ‚Äì July 19, 2020 using an online questionnaire that was completed by 3,000 U.S. adults (age 18+) that were recruited from an Internet panel that matches the characteristics of the U.S. population as estimated in the U.S. Census. Following WX17, WX18, and WX19, which were designed to establish baseline measures of the extent to which U.S. adults receive, understand, and respond to severe weather forecasts and warnings, WX20 was designed to continue and, in some cases, refine the measurement of these concepts. Additionally, WX20 measured public trust in the National Weather Service (NWS), extreme weather and climate risk perceptions, risk literacy, interpretations of probabilistic language, and perceptions the accuracy of weather information.&#39;,
    &#39;published_at&#39;: &#39;2020-09-01T14:03:39Z&#39;,
    &#39;publisher&#39;: &#39;Extreme Weather and Society Survey&#39;,
    &#39;citationHtml&#39;: &#39;Ripberger, Joseph; Krocak, Makenzie; Silva, Carol; Jenkins-Smith, Hank, 2020, &quot;WX20&quot;, &lt;a href=&quot;https://doi.org/10.7910/DVN/EWOCUA&quot; target=&quot;_blank&quot;&gt;https://doi.org/10.7910/DVN/EWOCUA&lt;/a&gt;, Harvard Dataverse, V2, UNF:6:+s2ce53I39wFRTp442tBEQ== [fileUNF]&#39;,
    &#39;identifier_of_dataverse&#39;: &#39;wxsurvey&#39;,
    &#39;name_of_dataverse&#39;: &#39;Extreme Weather and Society Survey&#39;,
    &#39;citation&#39;: &#39;Ripberger, Joseph; Krocak, Makenzie; Silva, Carol; Jenkins-Smith, Hank, 2020, &quot;WX20&quot;, https://doi.org/10.7910/DVN/EWOCUA, Harvard Dataverse, V2, UNF:6:+s2ce53I39wFRTp442tBEQ== [fileUNF]&#39;,
    &#39;publicationStatuses&#39;: [&#39;Published&#39;],
    &#39;storageIdentifier&#39;: &#39;s3://10.7910/DVN/EWOCUA&#39;,
    &#39;subjects&#39;: [&#39;Social Sciences&#39;],
    &#39;fileCount&#39;: 3,
    &#39;versionId&#39;: 210553,
    &#39;versionState&#39;: &#39;RELEASED&#39;,
    &#39;majorVersion&#39;: 2,
    &#39;minorVersion&#39;: 1,
    &#39;createdAt&#39;: &#39;2020-08-05T13:29:07Z&#39;,
    &#39;updatedAt&#39;: &#39;2020-09-01T14:46:05Z&#39;,
    &#39;contacts&#39;: [{&#39;name&#39;: &#39;Ripberger, Joseph&#39;,
      &#39;affiliation&#39;: &#39;University of Oklahoma&#39;}],
    &#39;publications&#39;: [{}],
    &#39;authors&#39;: [&#39;Ripberger, Joseph&#39;,
     &#39;Krocak, Makenzie&#39;,
     &#39;Silva, Carol&#39;,
     &#39;Jenkins-Smith, Hank&#39;]},
   {&#39;name&#39;: &#39;TC21&#39;,
    &#39;type&#39;: &#39;dataset&#39;,
    &#39;url&#39;: &#39;https://doi.org/10.7910/DVN/Q2S7OJ&#39;,
    &#39;image_url&#39;: &#39;https://dataverse.harvard.edu/api/datasets/6100464/logo&#39;,
    &#39;global_id&#39;: &#39;doi:10.7910/DVN/Q2S7OJ&#39;,
    &#39;description&#39;: &#39;This report describes the results of a nationwide survey on tropical cyclones in the United States. The 2021 Tropical Cyclone Survey (TC21) was designed and administered by the Institute for Public Policy Research and Analysis (IPPRA) at the University of Oklahoma. It was fielded June 22 ‚Äì July 1, 2021, using an online questionnaire that was completed by 1,550 U.S. adults (age 18+) that were recruited from an Internet panel that matches the characteristics of the U.S. population as estimated in the U.S. Census. The TC20 survey was designed to establish baseline measures of the extent to which U.S. adults receive, understand, and respond to tropical cyclone forecasts and warnings as well as trust in the National Weather Service (NWS), extreme weather and climate risk perceptions, risk literacy, interpretations of probabilistic language, and weather preparedness. The TC21 survey refined these measures and included a few questions about information preferences along the event timeline. This report briefly describes the methodology, survey data collection, data weighting, and a reproduction of the survey instrument with weighted means and frequencies for the questions that elicited numeric responses. The University of Oklahoma provided funding for all data collection. NOAA‚Äôs Weather Program Office through the U.S. Weather Research Program provided funding for survey design and data analysis.&#39;,
    &#39;published_at&#39;: &#39;2022-04-05T14:55:39Z&#39;,
    &#39;publisher&#39;: &#39;Extreme Weather and Society Survey&#39;,
    &#39;citationHtml&#39;: &#39;Krocak, Makenzie; Ripberger, Joseph; Silva, Carol; Jenkins-Smith, Hank, 2022, &quot;TC21&quot;, &lt;a href=&quot;https://doi.org/10.7910/DVN/Q2S7OJ&quot; target=&quot;_blank&quot;&gt;https://doi.org/10.7910/DVN/Q2S7OJ&lt;/a&gt;, Harvard Dataverse, V2, UNF:6:c6gXgLQMWXjgC6yBa2bubA== [fileUNF]&#39;,
    &#39;identifier_of_dataverse&#39;: &#39;wxsurvey&#39;,
    &#39;name_of_dataverse&#39;: &#39;Extreme Weather and Society Survey&#39;,
    &#39;citation&#39;: &#39;Krocak, Makenzie; Ripberger, Joseph; Silva, Carol; Jenkins-Smith, Hank, 2022, &quot;TC21&quot;, https://doi.org/10.7910/DVN/Q2S7OJ, Harvard Dataverse, V2, UNF:6:c6gXgLQMWXjgC6yBa2bubA== [fileUNF]&#39;,
    &#39;publicationStatuses&#39;: [&#39;Published&#39;],
    &#39;storageIdentifier&#39;: &#39;s3://10.7910/DVN/Q2S7OJ&#39;,
    &#39;subjects&#39;: [&#39;Social Sciences&#39;],
    &#39;fileCount&#39;: 3,
    &#39;versionId&#39;: 324222,
    &#39;versionState&#39;: &#39;RELEASED&#39;,
    &#39;majorVersion&#39;: 2,
    &#39;minorVersion&#39;: 0,
    &#39;createdAt&#39;: &#39;2022-03-16T19:46:41Z&#39;,
    &#39;updatedAt&#39;: &#39;2022-04-05T14:55:39Z&#39;,
    &#39;contacts&#39;: [{&#39;name&#39;: &#39;Krocak, Makenzie&#39;,
      &#39;affiliation&#39;: &#39;University of Oklahoma&#39;}],
    &#39;authors&#39;: [&#39;Krocak, Makenzie&#39;,
     &#39;Ripberger, Joseph&#39;,
     &#39;Silva, Carol&#39;,
     &#39;Jenkins-Smith, Hank&#39;]},
   {&#39;name&#39;: &#39;WX21&#39;,
    &#39;type&#39;: &#39;dataset&#39;,
    &#39;url&#39;: &#39;https://doi.org/10.7910/DVN/QYZLSO&#39;,
    &#39;image_url&#39;: &#39;https://dataverse.harvard.edu/api/datasets/4882756/logo&#39;,
    &#39;global_id&#39;: &#39;doi:10.7910/DVN/QYZLSO&#39;,
    &#39;description&#39;: &#39;The Severe Weather and Society Survey (WX) was designed and administered by the Center for Risk and Crisis Management (CRCM) at the University of Oklahoma. This is the fifth survey in the annual series (see Silva et al. 2017, Silva et al. 2018, Silva et al. 2019, and Krocak et al. 2020 for information on WX17, WX18, WX19, and WX20). WX21 was fielded June 9 ‚Äì July 17, 2021 using an online questionnaire that was completed by 1,550 US adults (age 18+) that were recruited from an Internet panel that matches the characteristics of the U.S. population as estimated in the U.S. Census. WX17 and WX18 were designed to establish baseline measures of the extent to which US adults receive, understand, and respond to severe weather forecasts and warnings; WX19 and WX20 were designed to continue and, in some cases, refine the measurement of these concepts. WX21 continues to measure these core concepts, giving us 5 years of consistent data to continue measuring change. Additionally, WX21 measured public trust in the National Weather Service (NWS), extreme weather and climate risk perceptions, risk literacy, interpretations of probabilistic language, and interpretation of longer-range severe weather forecasts (like those from the NOAA Storm Prediction Center).&#39;,
    &#39;published_at&#39;: &#39;2022-08-22T20:37:58Z&#39;,
    &#39;publisher&#39;: &#39;Extreme Weather and Society Survey&#39;,
    &#39;citationHtml&#39;: &#39;Ripberger, Joseph; Krocak, Makenzie; Silva, Carol; Jenkins-Smith, Hank, 2021, &quot;WX21&quot;, &lt;a href=&quot;https://doi.org/10.7910/DVN/QYZLSO&quot; target=&quot;_blank&quot;&gt;https://doi.org/10.7910/DVN/QYZLSO&lt;/a&gt;, Harvard Dataverse, V2, UNF:6:Z2TF/SuLbAgTzrdUBe1+rw== [fileUNF]&#39;,
    &#39;identifier_of_dataverse&#39;: &#39;wxsurvey&#39;,
    &#39;name_of_dataverse&#39;: &#39;Extreme Weather and Society Survey&#39;,
    &#39;citation&#39;: &#39;Ripberger, Joseph; Krocak, Makenzie; Silva, Carol; Jenkins-Smith, Hank, 2021, &quot;WX21&quot;, https://doi.org/10.7910/DVN/QYZLSO, Harvard Dataverse, V2, UNF:6:Z2TF/SuLbAgTzrdUBe1+rw== [fileUNF]&#39;,
    &#39;publicationStatuses&#39;: [&#39;Published&#39;],
    &#39;storageIdentifier&#39;: &#39;s3://10.7910/DVN/QYZLSO&#39;,
    &#39;subjects&#39;: [&#39;Social Sciences&#39;],
    &#39;fileCount&#39;: 3,
    &#39;versionId&#39;: 331449,
    &#39;versionState&#39;: &#39;RELEASED&#39;,
    &#39;majorVersion&#39;: 2,
    &#39;minorVersion&#39;: 0,
    &#39;createdAt&#39;: &#39;2021-07-08T16:26:55Z&#39;,
    &#39;updatedAt&#39;: &#39;2022-08-22T20:37:58Z&#39;,
    &#39;contacts&#39;: [{&#39;name&#39;: &#39;Krocak, Makenzie&#39;,
      &#39;affiliation&#39;: &#39;University of Oklahoma&#39;}],
    &#39;authors&#39;: [&#39;Ripberger, Joseph&#39;,
     &#39;Krocak, Makenzie&#39;,
     &#39;Silva, Carol&#39;,
     &#39;Jenkins-Smith, Hank&#39;]},
   {&#39;name&#39;: &#39;TC20&#39;,
    &#39;type&#39;: &#39;dataset&#39;,
    &#39;url&#39;: &#39;https://doi.org/10.7910/DVN/QUO60T&#39;,
    &#39;image_url&#39;: &#39;https://dataverse.harvard.edu/api/datasets/6100449/logo&#39;,
    &#39;global_id&#39;: &#39;doi:10.7910/DVN/QUO60T&#39;,
    &#39;description&#39;: &#39;This report describes the results of a nationwide survey on tropical cyclones in the United States. The Tropical Cyclone Survey (TC20) was designed and administered by the Center for Risk and Crisis Management (CRCM) at the University of Oklahoma. It was fielded June 29 ‚Äì July 2, 2020, using an online questionnaire that was completed by 1,000 U.S. adults (age 18+) that were recruited from an Internet panel that matches the characteristics of the U.S. population as estimated in the U.S. Census. The TC20 survey was designed to establish baseline measures of the extent to which U.S. adults receive, understand, and respond to tropical cyclone forecasts and warnings. The survey also measured public trust in the National Weather Service (NWS), extreme weather and climate risk perceptions, risk literacy, interpretations of probabilistic language, and weather preparedness. This report briefly describes the methodology, survey data collection, data weighting, and a reproduction of the survey instrument with weighted means and frequencies for the questions that elicited numeric responses. The University of Oklahoma provided funding for all data collection. NOAA‚Äôs Weather Program Office through the U.S. Weather Research Program provided funding for survey design and data analysis.&#39;,
    &#39;published_at&#39;: &#39;2022-03-16T19:43:24Z&#39;,
    &#39;publisher&#39;: &#39;Extreme Weather and Society Survey&#39;,
    &#39;citationHtml&#39;: &#39;Ripberger, Joseph; Silva, Carol; Jenkins-Smith, Hank; Allan, Jinan; Krocak, Makenzie, 2022, &quot;TC20&quot;, &lt;a href=&quot;https://doi.org/10.7910/DVN/QUO60T&quot; target=&quot;_blank&quot;&gt;https://doi.org/10.7910/DVN/QUO60T&lt;/a&gt;, Harvard Dataverse, V2, UNF:6:FawaZS0ZTU6HjFBdel6apw== [fileUNF]&#39;,
    &#39;identifier_of_dataverse&#39;: &#39;wxsurvey&#39;,
    &#39;name_of_dataverse&#39;: &#39;Extreme Weather and Society Survey&#39;,
    &#39;citation&#39;: &#39;Ripberger, Joseph; Silva, Carol; Jenkins-Smith, Hank; Allan, Jinan; Krocak, Makenzie, 2022, &quot;TC20&quot;, https://doi.org/10.7910/DVN/QUO60T, Harvard Dataverse, V2, UNF:6:FawaZS0ZTU6HjFBdel6apw== [fileUNF]&#39;,
    &#39;publicationStatuses&#39;: [&#39;Published&#39;],
    &#39;storageIdentifier&#39;: &#39;s3://10.7910/DVN/QUO60T&#39;,
    &#39;subjects&#39;: [&#39;Social Sciences&#39;],
    &#39;fileCount&#39;: 3,
    &#39;versionId&#39;: 323596,
    &#39;versionState&#39;: &#39;RELEASED&#39;,
    &#39;majorVersion&#39;: 2,
    &#39;minorVersion&#39;: 2,
    &#39;createdAt&#39;: &#39;2022-03-16T18:41:30Z&#39;,
    &#39;updatedAt&#39;: &#39;2022-03-22T19:19:29Z&#39;,
    &#39;contacts&#39;: [{&#39;name&#39;: &#39;Krocak, Makenzie&#39;,
      &#39;affiliation&#39;: &#39;University of Oklahoma&#39;}],
    &#39;authors&#39;: [&#39;Ripberger, Joseph&#39;,
     &#39;Silva, Carol&#39;,
     &#39;Jenkins-Smith, Hank&#39;,
     &#39;Allan, Jinan&#39;,
     &#39;Krocak, Makenzie&#39;]},
   {&#39;name&#39;: &#39;Replication Data for: &quot;Seeing lies and laying blame: Partisanship and US public perceptions about disinformation&quot;&#39;,
    &#39;type&#39;: &#39;dataset&#39;,
    &#39;url&#39;: &#39;https://doi.org/10.7910/DVN/PRP4WX&#39;,
    &#39;image_url&#39;: &#39;https://dataverse.harvard.edu/api/datasets/8137610/logo&#39;,
    &#39;global_id&#39;: &#39;doi:10.7910/DVN/PRP4WX&#39;,
    &#39;description&#39;: &#39;These are the replication materials for &quot;Seeing lies and laying blame: Partisanship and US public perceptions about disinformation&quot; by Kaitlin Peach, Joseph Ripberger, Kuhika Gupta, Andrew Fox, Hank Jenkins-Smith, and Carol Silva. The data comes from the 2021 National Security Survey (NS21) administered by the Institute for Public Policy Research and Analysis (IPPRA) at the University of Oklahoma. The survey was fielded in December 2021, using an online questionnaire of 2,036 US adults (18+). The sample matches the characteristics of the U.S. population. This dataset only contains questions used in the study. A document detailing the survey questions with variable names, the R script, and CSV dataset are included. Funding for data collection was provided by the Office of the Vice President for Research and Partnerships at the University of Oklahoma.&#39;,
    &#39;published_at&#39;: &#39;2024-01-24T15:47:54Z&#39;,
    &#39;publisher&#39;: &#39;Harvard Dataverse&#39;,
    &#39;citationHtml&#39;: &#39;Kaitlin Peach; Joseph Ripberger; Kuhika Gupta; Andrew Fox; Hank Jenkins-Smith; Carol Silva, 2024, &quot;Replication Data for: &amp;quot;Seeing lies and laying blame: Partisanship and US public perceptions about disinformation&amp;quot;&quot;, &lt;a href=&quot;https://doi.org/10.7910/DVN/PRP4WX&quot; target=&quot;_blank&quot;&gt;https://doi.org/10.7910/DVN/PRP4WX&lt;/a&gt;, Harvard Dataverse, V1, UNF:6:vrIVJvf7xQUkor0v4gC74A== [fileUNF]&#39;,
    &#39;identifier_of_dataverse&#39;: &#39;harvard&#39;,
    &#39;name_of_dataverse&#39;: &#39;Harvard Dataverse&#39;,
    &#39;citation&#39;: &#39;Kaitlin Peach; Joseph Ripberger; Kuhika Gupta; Andrew Fox; Hank Jenkins-Smith; Carol Silva, 2024, &quot;Replication Data for: &quot;Seeing lies and laying blame: Partisanship and US public perceptions about disinformation&quot;&quot;, https://doi.org/10.7910/DVN/PRP4WX, Harvard Dataverse, V1, UNF:6:vrIVJvf7xQUkor0v4gC74A== [fileUNF]&#39;,
    &#39;publicationStatuses&#39;: [&#39;Published&#39;],
    &#39;storageIdentifier&#39;: &#39;s3://10.7910/DVN/PRP4WX&#39;,
    &#39;keywords&#39;: [&#39;disinformation&#39;],
    &#39;subjects&#39;: [&#39;Social Sciences&#39;],
    &#39;fileCount&#39;: 3,
    &#39;versionId&#39;: 369898,
    &#39;versionState&#39;: &#39;RELEASED&#39;,
    &#39;majorVersion&#39;: 1,
    &#39;minorVersion&#39;: 2,
    &#39;createdAt&#39;: &#39;2024-01-24T15:30:12Z&#39;,
    &#39;updatedAt&#39;: &#39;2024-01-24T16:56:11Z&#39;,
    &#39;contacts&#39;: [{&#39;name&#39;: &#39;Peach, Kaitlin&#39;,
      &#39;affiliation&#39;: &#39;University of Oklahoma&#39;}],
    &#39;publications&#39;: [{}],
    &#39;authors&#39;: [&#39;Kaitlin Peach&#39;,
     &#39;Joseph Ripberger&#39;,
     &#39;Kuhika Gupta&#39;,
     &#39;Andrew Fox&#39;,
     &#39;Hank Jenkins-Smith&#39;,
     &#39;Carol Silva&#39;]}],
  &#39;count_in_response&#39;: 10}}
</pre></div>
</div>
</div>
</div>
</section>
<section id="transform-the-json-results">
<h3>Transform the JSON results<a class="headerlink" href="#transform-the-json-results" title="Link to this heading">#</a></h3>
<p>We can easily transform the JSON results into a more readable format, a Pandas dataframe.  This bit of code we can keep separate or build into any cells where the results are returned in JSON.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Extract items and load into DataFrame</span>
<span class="n">items</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="s1">&#39;items&#39;</span><span class="p">]</span>
<span class="n">df_results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">items</span><span class="p">)</span>

<span class="c1"># Preview first 5 rows</span>
<span class="n">df_results</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>name</th>
      <th>type</th>
      <th>url</th>
      <th>global_id</th>
      <th>description</th>
      <th>published_at</th>
      <th>publisher</th>
      <th>citationHtml</th>
      <th>identifier_of_dataverse</th>
      <th>name_of_dataverse</th>
      <th>...</th>
      <th>versionState</th>
      <th>majorVersion</th>
      <th>minorVersion</th>
      <th>createdAt</th>
      <th>updatedAt</th>
      <th>contacts</th>
      <th>publications</th>
      <th>authors</th>
      <th>image_url</th>
      <th>keywords</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>A comprehensive inventory and review of color ...</td>
      <td>dataset</td>
      <td>https://doi.org/10.7910/DVN/IFBAZ4</td>
      <td>doi:10.7910/DVN/IFBAZ4</td>
      <td>This dataset contains an inventory of colors u...</td>
      <td>2025-04-22T13:26:32Z</td>
      <td>Harvard Dataverse</td>
      <td>Ripberger, Joseph; Bitterman, Abby; Rosen, Zoe...</td>
      <td>harvard</td>
      <td>Harvard Dataverse</td>
      <td>...</td>
      <td>RELEASED</td>
      <td>1</td>
      <td>0</td>
      <td>2025-03-27T13:54:15Z</td>
      <td>2025-04-22T13:26:32Z</td>
      <td>[{'name': 'Ripberger, Joseph', 'affiliation': ...</td>
      <td>[{}]</td>
      <td>[Ripberger, Joseph, Bitterman, Abby, Rosen, Zoey]</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>S3OK Surveys</td>
      <td>dataset</td>
      <td>https://doi.org/10.7910/DVN/JHLMBU</td>
      <td>doi:10.7910/DVN/JHLMBU</td>
      <td>This repository contains data and accompanying...</td>
      <td>2025-08-29T11:02:55Z</td>
      <td>The Oklahoma Meso-Scale Integrated Socio-Geogr...</td>
      <td>Ripberger, Joseph; Jenkins-Smith, Hank; Carlso...</td>
      <td>msisnet</td>
      <td>The Oklahoma Meso-Scale Integrated Socio-Geogr...</td>
      <td>...</td>
      <td>RELEASED</td>
      <td>1</td>
      <td>0</td>
      <td>2025-08-26T18:21:10Z</td>
      <td>2025-08-29T11:02:55Z</td>
      <td>[{'name': 'Ripberger, Joseph', 'affiliation': ...</td>
      <td>[{}]</td>
      <td>[Ripberger, Joseph, Ripberger, Joseph, Jenkins...</td>
      <td>https://dataverse.harvard.edu/api/datasets/120...</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>WX18</td>
      <td>dataset</td>
      <td>https://doi.org/10.7910/DVN/RHT4ON</td>
      <td>doi:10.7910/DVN/RHT4ON</td>
      <td>The Severe Weather and Society Survey (WX) was...</td>
      <td>2020-02-03T22:11:23Z</td>
      <td>Extreme Weather and Society Survey</td>
      <td>Ripberger, Joseph; Silva, Carol; Jenkins-Smith...</td>
      <td>wxsurvey</td>
      <td>Extreme Weather and Society Survey</td>
      <td>...</td>
      <td>RELEASED</td>
      <td>1</td>
      <td>1</td>
      <td>2020-01-13T14:26:39Z</td>
      <td>2020-09-01T14:43:00Z</td>
      <td>[{'name': 'Ripberger, Joseph', 'affiliation': ...</td>
      <td>[{}]</td>
      <td>[Ripberger, Joseph, Silva, Carol, Jenkins-Smit...</td>
      <td>https://dataverse.harvard.edu/api/datasets/365...</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>3</th>
      <td>WX19</td>
      <td>dataset</td>
      <td>https://doi.org/10.7910/DVN/MLCJEW</td>
      <td>doi:10.7910/DVN/MLCJEW</td>
      <td>The Severe Weather and Society Survey (WX) was...</td>
      <td>2020-02-03T22:10:59Z</td>
      <td>Extreme Weather and Society Survey</td>
      <td>Ripberger, Joseph; Silva, Carol; Jenkins-Smith...</td>
      <td>wxsurvey</td>
      <td>Extreme Weather and Society Survey</td>
      <td>...</td>
      <td>RELEASED</td>
      <td>1</td>
      <td>1</td>
      <td>2020-01-13T14:28:14Z</td>
      <td>2020-09-01T14:43:57Z</td>
      <td>[{'name': 'Ripberger, Joseph', 'affiliation': ...</td>
      <td>[{}]</td>
      <td>[Ripberger, Joseph, Silva, Carol, Jenkins-Smit...</td>
      <td>https://dataverse.harvard.edu/api/datasets/365...</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4</th>
      <td>WX17</td>
      <td>dataset</td>
      <td>https://doi.org/10.7910/DVN/GSTYK4</td>
      <td>doi:10.7910/DVN/GSTYK4</td>
      <td>The Severe Weather and Society Survey (WX17) w...</td>
      <td>2020-02-03T22:10:34Z</td>
      <td>Extreme Weather and Society Survey</td>
      <td>Ripberger, Joseph; Silva, Carol; Jenkins-Smith...</td>
      <td>wxsurvey</td>
      <td>Extreme Weather and Society Survey</td>
      <td>...</td>
      <td>RELEASED</td>
      <td>1</td>
      <td>1</td>
      <td>2020-01-28T20:00:17Z</td>
      <td>2020-09-01T14:41:58Z</td>
      <td>[{'name': 'Ripberger, Joseph', 'affiliation': ...</td>
      <td>[{}]</td>
      <td>[Ripberger, Joseph, Silva, Carol, Jenkins-Smit...</td>
      <td>https://dataverse.harvard.edu/api/datasets/367...</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>5 rows √ó 26 columns</p>
</div></div></div>
</div>
</section>
<section id="search-for-more-than-10-results">
<h3>Search for more than 10 results<a class="headerlink" href="#search-for-more-than-10-results" title="Link to this heading">#</a></h3>
<p>We can make an API call that goes beyond the 10 result limit by creating a <strong>loop</strong>.  The ‚Äúwhile True‚Äù statement will continue running (10 results at a time) until there are no results remaining.  We collect all of the results in one list using the ‚Äúextend‚Äù command.  Finally, we can limit the dataframe to only view a subset of columns.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;ripberger&quot;</span>
<span class="n">start</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">per_page</span> <span class="o">=</span> <span class="mi">20</span>  <span class="c1"># Max per page is 100</span>
<span class="n">all_items</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
    <span class="n">search_url</span> <span class="o">=</span> <span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;https://dataverse.harvard.edu/api/search?&quot;</span>
        <span class="sa">f</span><span class="s2">&quot;q=</span><span class="si">{</span><span class="n">query</span><span class="si">}</span><span class="s2">&amp;type=dataset&amp;start=</span><span class="si">{</span><span class="n">start</span><span class="si">}</span><span class="s2">&amp;per_page=</span><span class="si">{</span><span class="n">per_page</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="p">)</span>
    
    <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">search_url</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
    
    <span class="n">items</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="s1">&#39;items&#39;</span><span class="p">]</span>
    <span class="n">all_items</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">items</span><span class="p">)</span>
    
    <span class="c1"># Break if fewer than per_page results are returned (i.e., last page)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">items</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">per_page</span><span class="p">:</span>
        <span class="k">break</span>
    <span class="n">start</span> <span class="o">+=</span> <span class="n">per_page</span>

<span class="c1"># Convert to DataFrame</span>
<span class="n">df_results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">all_items</span><span class="p">)</span>
<span class="n">df_results</span><span class="p">[[</span><span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="s1">&#39;global_id&#39;</span><span class="p">,</span> <span class="s1">&#39;published_at&#39;</span><span class="p">,</span> <span class="s1">&#39;citation&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>name</th>
      <th>global_id</th>
      <th>published_at</th>
      <th>citation</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>A comprehensive inventory and review of color ...</td>
      <td>doi:10.7910/DVN/IFBAZ4</td>
      <td>2025-04-22T13:26:32Z</td>
      <td>Ripberger, Joseph; Bitterman, Abby; Rosen, Zoe...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>S3OK Surveys</td>
      <td>doi:10.7910/DVN/JHLMBU</td>
      <td>2025-08-29T11:02:55Z</td>
      <td>Ripberger, Joseph; Jenkins-Smith, Hank; Carlso...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>WX18</td>
      <td>doi:10.7910/DVN/RHT4ON</td>
      <td>2020-02-03T22:11:23Z</td>
      <td>Ripberger, Joseph; Silva, Carol; Jenkins-Smith...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>WX19</td>
      <td>doi:10.7910/DVN/MLCJEW</td>
      <td>2020-02-03T22:10:59Z</td>
      <td>Ripberger, Joseph; Silva, Carol; Jenkins-Smith...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>WX17</td>
      <td>doi:10.7910/DVN/GSTYK4</td>
      <td>2020-02-03T22:10:34Z</td>
      <td>Ripberger, Joseph; Silva, Carol; Jenkins-Smith...</td>
    </tr>
    <tr>
      <th>5</th>
      <td>WX20</td>
      <td>doi:10.7910/DVN/EWOCUA</td>
      <td>2020-09-01T14:03:39Z</td>
      <td>Ripberger, Joseph; Krocak, Makenzie; Silva, Ca...</td>
    </tr>
    <tr>
      <th>6</th>
      <td>TC21</td>
      <td>doi:10.7910/DVN/Q2S7OJ</td>
      <td>2022-04-05T14:55:39Z</td>
      <td>Krocak, Makenzie; Ripberger, Joseph; Silva, Ca...</td>
    </tr>
    <tr>
      <th>7</th>
      <td>WX21</td>
      <td>doi:10.7910/DVN/QYZLSO</td>
      <td>2022-08-22T20:37:58Z</td>
      <td>Ripberger, Joseph; Krocak, Makenzie; Silva, Ca...</td>
    </tr>
    <tr>
      <th>8</th>
      <td>TC20</td>
      <td>doi:10.7910/DVN/QUO60T</td>
      <td>2022-03-16T19:43:24Z</td>
      <td>Ripberger, Joseph; Silva, Carol; Jenkins-Smith...</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Replication Data for: "Seeing lies and laying ...</td>
      <td>doi:10.7910/DVN/PRP4WX</td>
      <td>2024-01-24T15:47:54Z</td>
      <td>Kaitlin Peach; Joseph Ripberger; Kuhika Gupta;...</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#How many datasets?  Each row (first number) represents a dataset.</span>
<span class="n">df_results</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(39, 26)
</pre></div>
</div>
</div>
</div>
</section>
<section id="subsetting-our-results">
<h3>Subsetting Our Results<a class="headerlink" href="#subsetting-our-results" title="Link to this heading">#</a></h3>
<p>Let‚Äôs say we don‚Äôt want all of these, but only a subset of related surveys.  For this step, and the remainder of notebook, we will focus on the yearly waves of the Extreme Weather and Society Survey (WXYY). So let‚Äôs subset them the dataframe from the earlier API call.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define the dataset names you want to filter on</span>
<span class="n">target_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;WX17&quot;</span><span class="p">,</span> <span class="s2">&quot;WX18&quot;</span><span class="p">,</span> <span class="s2">&quot;WX19&quot;</span><span class="p">,</span> <span class="s2">&quot;WX20&quot;</span><span class="p">,</span> <span class="s2">&quot;WX21&quot;</span><span class="p">,</span> <span class="s2">&quot;WX22&quot;</span><span class="p">,</span> <span class="s2">&quot;WX23&quot;</span><span class="p">,</span> <span class="s2">&quot;WX24&quot;</span><span class="p">]</span>

<span class="c1"># Subset the dataframe</span>
<span class="n">df_subset</span> <span class="o">=</span> <span class="n">df_results</span><span class="p">[</span><span class="n">df_results</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">target_names</span><span class="p">)]</span>

<span class="c1"># Display the result</span>
<span class="n">df_subset</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>name</th>
      <th>type</th>
      <th>url</th>
      <th>global_id</th>
      <th>description</th>
      <th>published_at</th>
      <th>publisher</th>
      <th>citationHtml</th>
      <th>identifier_of_dataverse</th>
      <th>name_of_dataverse</th>
      <th>...</th>
      <th>versionState</th>
      <th>majorVersion</th>
      <th>minorVersion</th>
      <th>createdAt</th>
      <th>updatedAt</th>
      <th>contacts</th>
      <th>publications</th>
      <th>authors</th>
      <th>image_url</th>
      <th>keywords</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2</th>
      <td>WX18</td>
      <td>dataset</td>
      <td>https://doi.org/10.7910/DVN/RHT4ON</td>
      <td>doi:10.7910/DVN/RHT4ON</td>
      <td>The Severe Weather and Society Survey (WX) was...</td>
      <td>2020-02-03T22:11:23Z</td>
      <td>Extreme Weather and Society Survey</td>
      <td>Ripberger, Joseph; Silva, Carol; Jenkins-Smith...</td>
      <td>wxsurvey</td>
      <td>Extreme Weather and Society Survey</td>
      <td>...</td>
      <td>RELEASED</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>2020-01-13T14:26:39Z</td>
      <td>2020-09-01T14:43:00Z</td>
      <td>[{'name': 'Ripberger, Joseph', 'affiliation': ...</td>
      <td>[{}]</td>
      <td>[Ripberger, Joseph, Silva, Carol, Jenkins-Smit...</td>
      <td>https://dataverse.harvard.edu/api/datasets/365...</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>3</th>
      <td>WX19</td>
      <td>dataset</td>
      <td>https://doi.org/10.7910/DVN/MLCJEW</td>
      <td>doi:10.7910/DVN/MLCJEW</td>
      <td>The Severe Weather and Society Survey (WX) was...</td>
      <td>2020-02-03T22:10:59Z</td>
      <td>Extreme Weather and Society Survey</td>
      <td>Ripberger, Joseph; Silva, Carol; Jenkins-Smith...</td>
      <td>wxsurvey</td>
      <td>Extreme Weather and Society Survey</td>
      <td>...</td>
      <td>RELEASED</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>2020-01-13T14:28:14Z</td>
      <td>2020-09-01T14:43:57Z</td>
      <td>[{'name': 'Ripberger, Joseph', 'affiliation': ...</td>
      <td>[{}]</td>
      <td>[Ripberger, Joseph, Silva, Carol, Jenkins-Smit...</td>
      <td>https://dataverse.harvard.edu/api/datasets/365...</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4</th>
      <td>WX17</td>
      <td>dataset</td>
      <td>https://doi.org/10.7910/DVN/GSTYK4</td>
      <td>doi:10.7910/DVN/GSTYK4</td>
      <td>The Severe Weather and Society Survey (WX17) w...</td>
      <td>2020-02-03T22:10:34Z</td>
      <td>Extreme Weather and Society Survey</td>
      <td>Ripberger, Joseph; Silva, Carol; Jenkins-Smith...</td>
      <td>wxsurvey</td>
      <td>Extreme Weather and Society Survey</td>
      <td>...</td>
      <td>RELEASED</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>2020-01-28T20:00:17Z</td>
      <td>2020-09-01T14:41:58Z</td>
      <td>[{'name': 'Ripberger, Joseph', 'affiliation': ...</td>
      <td>[{}]</td>
      <td>[Ripberger, Joseph, Silva, Carol, Jenkins-Smit...</td>
      <td>https://dataverse.harvard.edu/api/datasets/367...</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>5</th>
      <td>WX20</td>
      <td>dataset</td>
      <td>https://doi.org/10.7910/DVN/EWOCUA</td>
      <td>doi:10.7910/DVN/EWOCUA</td>
      <td>The Severe Weather and Society Survey (WX) was...</td>
      <td>2020-09-01T14:03:39Z</td>
      <td>Extreme Weather and Society Survey</td>
      <td>Ripberger, Joseph; Krocak, Makenzie; Silva, Ca...</td>
      <td>wxsurvey</td>
      <td>Extreme Weather and Society Survey</td>
      <td>...</td>
      <td>RELEASED</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>2020-08-05T13:29:07Z</td>
      <td>2020-09-01T14:46:05Z</td>
      <td>[{'name': 'Ripberger, Joseph', 'affiliation': ...</td>
      <td>[{}]</td>
      <td>[Ripberger, Joseph, Krocak, Makenzie, Silva, C...</td>
      <td>https://dataverse.harvard.edu/api/datasets/400...</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>7</th>
      <td>WX21</td>
      <td>dataset</td>
      <td>https://doi.org/10.7910/DVN/QYZLSO</td>
      <td>doi:10.7910/DVN/QYZLSO</td>
      <td>The Severe Weather and Society Survey (WX) was...</td>
      <td>2022-08-22T20:37:58Z</td>
      <td>Extreme Weather and Society Survey</td>
      <td>Ripberger, Joseph; Krocak, Makenzie; Silva, Ca...</td>
      <td>wxsurvey</td>
      <td>Extreme Weather and Society Survey</td>
      <td>...</td>
      <td>RELEASED</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>2021-07-08T16:26:55Z</td>
      <td>2022-08-22T20:37:58Z</td>
      <td>[{'name': 'Krocak, Makenzie', 'affiliation': '...</td>
      <td>NaN</td>
      <td>[Ripberger, Joseph, Krocak, Makenzie, Silva, C...</td>
      <td>https://dataverse.harvard.edu/api/datasets/488...</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>14</th>
      <td>WX22</td>
      <td>dataset</td>
      <td>https://doi.org/10.7910/DVN/TD5DGD</td>
      <td>doi:10.7910/DVN/TD5DGD</td>
      <td>This report describes the results of an annual...</td>
      <td>2022-08-30T16:57:50Z</td>
      <td>Extreme Weather and Society Survey</td>
      <td>Bitterman, Abby; Krocak, Makenzie; Ripberger, ...</td>
      <td>wxsurvey</td>
      <td>Extreme Weather and Society Survey</td>
      <td>...</td>
      <td>RELEASED</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>2022-08-30T16:55:49Z</td>
      <td>2022-08-30T16:57:50Z</td>
      <td>[{'name': 'Krocak, Makenzie', 'affiliation': '...</td>
      <td>NaN</td>
      <td>[Bitterman, Abby, Krocak, Makenzie, Ripberger,...</td>
      <td>https://dataverse.harvard.edu/api/datasets/643...</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>17</th>
      <td>WX23</td>
      <td>dataset</td>
      <td>https://doi.org/10.7910/DVN/PPXI8H</td>
      <td>doi:10.7910/DVN/PPXI8H</td>
      <td>This report describes the results of an annual...</td>
      <td>2024-04-29T18:59:56Z</td>
      <td>Extreme Weather and Society Survey</td>
      <td>Bitterman, Abby; Krocak, Makenzie; Ripberger, ...</td>
      <td>wxsurvey</td>
      <td>Extreme Weather and Society Survey</td>
      <td>...</td>
      <td>RELEASED</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>2023-09-13T16:07:51Z</td>
      <td>2024-04-29T18:59:56Z</td>
      <td>[{'name': 'Krocak, Makenzie', 'affiliation': '...</td>
      <td>NaN</td>
      <td>[Bitterman, Abby, Krocak, Makenzie, Ripberger,...</td>
      <td>https://dataverse.harvard.edu/api/datasets/736...</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>20</th>
      <td>WX24</td>
      <td>dataset</td>
      <td>https://doi.org/10.7910/DVN/QMEKYJ</td>
      <td>doi:10.7910/DVN/QMEKYJ</td>
      <td>This report describes the results of an annual...</td>
      <td>2025-03-10T16:47:09Z</td>
      <td>Extreme Weather and Society Survey</td>
      <td>Bitterman, Abby; Krocak, Makenzie; Ripberger, ...</td>
      <td>wxsurvey</td>
      <td>Extreme Weather and Society Survey</td>
      <td>...</td>
      <td>RELEASED</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>2025-03-10T16:45:19Z</td>
      <td>2025-03-10T16:47:09Z</td>
      <td>[{'name': 'Krocak, Makenzie', 'affiliation': '...</td>
      <td>NaN</td>
      <td>[Bitterman, Abby, Krocak, Makenzie, Ripberger,...</td>
      <td>https://dataverse.harvard.edu/api/datasets/109...</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>8 rows √ó 26 columns</p>
</div></div></div>
</div>
</section>
</section>
<section id="step-1a-get-dataset-metadata-and-files">
<h2>Step 1a: Get Dataset Metadata and Files<a class="headerlink" href="#step-1a-get-dataset-metadata-and-files" title="Link to this heading">#</a></h2>
<section id="getting-metadata-for-a-single-dataset">
<h3>Getting metadata for a single dataset<a class="headerlink" href="#getting-metadata-for-a-single-dataset" title="Link to this heading">#</a></h3>
<p>Let‚Äôs examine the metadata for one of the datasets in the subset, WX18.  There will often be two sets of metadata: file-level (specific to the repository) and data-level (that describes the data‚Äîthe topic of yesterday‚Äôs forum).  In this example, we will first look at the file-level metadaa that the Dataverse uses.  Next, we will pull the full dataset metadata.  While the results will be in JSON, we will be adding a step that converts them to a Pandas dataframe.</p>
</section>
<section id="file-level-metadata">
<h3>File level metadata<a class="headerlink" href="#file-level-metadata" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Extract persistent ID (DOI) from the first row [0] by position</span>
<span class="n">persistent_id</span> <span class="o">=</span> <span class="n">df_subset</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;global_id&#39;</span><span class="p">]</span>

<span class="c1"># Get dataset metadata</span>
<span class="n">metadata_url</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;https://dataverse.harvard.edu/api/datasets/:persistentId/?persistentId=</span><span class="si">{</span><span class="n">persistent_id</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="n">metadata_response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">metadata_url</span><span class="p">)</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>

<span class="c1"># Get list of files</span>
<span class="n">files</span> <span class="o">=</span> <span class="n">metadata_response</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="s1">&#39;latestVersion&#39;</span><span class="p">][</span><span class="s1">&#39;files&#39;</span><span class="p">]</span>

<span class="c1"># Convert list of files to DataFrame</span>
<span class="n">df_files</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">files</span><span class="p">)</span>

<span class="c1"># Preview first few rows</span>
<span class="n">df_files</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>label</th>
      <th>restricted</th>
      <th>version</th>
      <th>datasetVersionId</th>
      <th>dataFile</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>WX18_data_wtd.tab</td>
      <td>False</td>
      <td>1</td>
      <td>210551</td>
      <td>{'id': 3657710, 'persistentId': 'doi:10.7910/D...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>WX18 Instrument.pdf</td>
      <td>False</td>
      <td>1</td>
      <td>210551</td>
      <td>{'id': 3657709, 'persistentId': 'doi:10.7910/D...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>WX18 Reference Report.pdf</td>
      <td>False</td>
      <td>1</td>
      <td>210551</td>
      <td>{'id': 3657708, 'persistentId': 'doi:10.7910/D...</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
<section id="full-dataset-metadata">
<h3>Full dataset metadata<a class="headerlink" href="#full-dataset-metadata" title="Link to this heading">#</a></h3>
<p>This is actually a case of where we want to see the full JSON, to view those aspects of the dataset that are most useful.  In this case, the most relevent information can be found in a description of the dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Extract persistent ID (DOI) from the first row</span>
<span class="n">persistent_id</span> <span class="o">=</span> <span class="n">df_subset</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;global_id&#39;</span><span class="p">]</span>

<span class="c1"># Get full dataset metadata (latest version)</span>
<span class="n">metadata_url</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;https://dataverse.harvard.edu/api/datasets/:persistentId/versions/:latest?persistentId=</span><span class="si">{</span><span class="n">persistent_id</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="n">metadata_response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">metadata_url</span><span class="p">)</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>

<span class="c1"># Extract list of files from the JSON</span>
<span class="n">files</span> <span class="o">=</span> <span class="n">metadata_response</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">][</span><span class="s1">&#39;files&#39;</span><span class="p">]</span>

<span class="n">metadata_response</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;status&#39;: &#39;OK&#39;,
 &#39;data&#39;: {&#39;id&#39;: 210551,
  &#39;datasetId&#39;: 3657707,
  &#39;datasetPersistentId&#39;: &#39;doi:10.7910/DVN/RHT4ON&#39;,
  &#39;datasetType&#39;: &#39;dataset&#39;,
  &#39;storageIdentifier&#39;: &#39;s3://10.7910/DVN/RHT4ON&#39;,
  &#39;versionNumber&#39;: 1,
  &#39;internalVersionNumber&#39;: 4,
  &#39;versionMinorNumber&#39;: 1,
  &#39;versionState&#39;: &#39;RELEASED&#39;,
  &#39;latestVersionPublishingState&#39;: &#39;RELEASED&#39;,
  &#39;deaccessionLink&#39;: &#39;&#39;,
  &#39;UNF&#39;: &#39;UNF:6:Yyyznfcg+cNLP/7D2v9/wg==&#39;,
  &#39;lastUpdateTime&#39;: &#39;2020-09-01T14:43:00Z&#39;,
  &#39;releaseTime&#39;: &#39;2020-09-01T14:43:00Z&#39;,
  &#39;createTime&#39;: &#39;2020-09-01T14:42:39Z&#39;,
  &#39;publicationDate&#39;: &#39;2020-02-03&#39;,
  &#39;citationDate&#39;: &#39;2020-02-03&#39;,
  &#39;license&#39;: {&#39;name&#39;: &#39;CC0 1.0&#39;,
   &#39;uri&#39;: &#39;http://creativecommons.org/publicdomain/zero/1.0&#39;,
   &#39;iconUri&#39;: &#39;https://licensebuttons.net/p/zero/1.0/88x31.png&#39;,
   &#39;rightsIdentifier&#39;: &#39;CC0-1.0&#39;,
   &#39;rightsIdentifierScheme&#39;: &#39;SPDX&#39;,
   &#39;schemeUri&#39;: &#39;https://spdx.org/licenses/&#39;,
   &#39;languageCode&#39;: &#39;en&#39;},
  &#39;fileAccessRequest&#39;: False,
  &#39;metadataBlocks&#39;: {&#39;citation&#39;: {&#39;displayName&#39;: &#39;Citation Metadata&#39;,
    &#39;name&#39;: &#39;citation&#39;,
    &#39;fields&#39;: [{&#39;typeName&#39;: &#39;title&#39;,
      &#39;multiple&#39;: False,
      &#39;typeClass&#39;: &#39;primitive&#39;,
      &#39;value&#39;: &#39;WX18&#39;},
     {&#39;typeName&#39;: &#39;author&#39;,
      &#39;multiple&#39;: True,
      &#39;typeClass&#39;: &#39;compound&#39;,
      &#39;value&#39;: [{&#39;authorName&#39;: {&#39;typeName&#39;: &#39;authorName&#39;,
         &#39;multiple&#39;: False,
         &#39;typeClass&#39;: &#39;primitive&#39;,
         &#39;value&#39;: &#39;Ripberger, Joseph&#39;},
        &#39;authorAffiliation&#39;: {&#39;typeName&#39;: &#39;authorAffiliation&#39;,
         &#39;multiple&#39;: False,
         &#39;typeClass&#39;: &#39;primitive&#39;,
         &#39;value&#39;: &#39;University of Oklahoma&#39;},
        &#39;authorIdentifierScheme&#39;: {&#39;typeName&#39;: &#39;authorIdentifierScheme&#39;,
         &#39;multiple&#39;: False,
         &#39;typeClass&#39;: &#39;controlledVocabulary&#39;,
         &#39;value&#39;: &#39;ORCID&#39;},
        &#39;authorIdentifier&#39;: {&#39;typeName&#39;: &#39;authorIdentifier&#39;,
         &#39;multiple&#39;: False,
         &#39;typeClass&#39;: &#39;primitive&#39;,
         &#39;value&#39;: &#39;0000-0003-0343-8262&#39;}},
       {&#39;authorName&#39;: {&#39;typeName&#39;: &#39;authorName&#39;,
         &#39;multiple&#39;: False,
         &#39;typeClass&#39;: &#39;primitive&#39;,
         &#39;value&#39;: &#39;Silva, Carol&#39;},
        &#39;authorAffiliation&#39;: {&#39;typeName&#39;: &#39;authorAffiliation&#39;,
         &#39;multiple&#39;: False,
         &#39;typeClass&#39;: &#39;primitive&#39;,
         &#39;value&#39;: &#39;University of Oklahoma&#39;},
        &#39;authorIdentifierScheme&#39;: {&#39;typeName&#39;: &#39;authorIdentifierScheme&#39;,
         &#39;multiple&#39;: False,
         &#39;typeClass&#39;: &#39;controlledVocabulary&#39;,
         &#39;value&#39;: &#39;ORCID&#39;},
        &#39;authorIdentifier&#39;: {&#39;typeName&#39;: &#39;authorIdentifier&#39;,
         &#39;multiple&#39;: False,
         &#39;typeClass&#39;: &#39;primitive&#39;,
         &#39;value&#39;: &#39;0000-0001-7171-6944&#39;}},
       {&#39;authorName&#39;: {&#39;typeName&#39;: &#39;authorName&#39;,
         &#39;multiple&#39;: False,
         &#39;typeClass&#39;: &#39;primitive&#39;,
         &#39;value&#39;: &#39;Jenkins-Smith, Hank&#39;},
        &#39;authorAffiliation&#39;: {&#39;typeName&#39;: &#39;authorAffiliation&#39;,
         &#39;multiple&#39;: False,
         &#39;typeClass&#39;: &#39;primitive&#39;,
         &#39;value&#39;: &#39;University of Oklahoma&#39;},
        &#39;authorIdentifierScheme&#39;: {&#39;typeName&#39;: &#39;authorIdentifierScheme&#39;,
         &#39;multiple&#39;: False,
         &#39;typeClass&#39;: &#39;controlledVocabulary&#39;,
         &#39;value&#39;: &#39;ORCID&#39;},
        &#39;authorIdentifier&#39;: {&#39;typeName&#39;: &#39;authorIdentifier&#39;,
         &#39;multiple&#39;: False,
         &#39;typeClass&#39;: &#39;primitive&#39;,
         &#39;value&#39;: &#39;0000-0002-5204-2726&#39;}},
       {&#39;authorName&#39;: {&#39;typeName&#39;: &#39;authorName&#39;,
         &#39;multiple&#39;: False,
         &#39;typeClass&#39;: &#39;primitive&#39;,
         &#39;value&#39;: &#39;Krocak, Makenzie&#39;},
        &#39;authorAffiliation&#39;: {&#39;typeName&#39;: &#39;authorAffiliation&#39;,
         &#39;multiple&#39;: False,
         &#39;typeClass&#39;: &#39;primitive&#39;,
         &#39;value&#39;: &#39;University of Oklahoma&#39;},
        &#39;authorIdentifierScheme&#39;: {&#39;typeName&#39;: &#39;authorIdentifierScheme&#39;,
         &#39;multiple&#39;: False,
         &#39;typeClass&#39;: &#39;controlledVocabulary&#39;,
         &#39;value&#39;: &#39;ORCID&#39;},
        &#39;authorIdentifier&#39;: {&#39;typeName&#39;: &#39;authorIdentifier&#39;,
         &#39;multiple&#39;: False,
         &#39;typeClass&#39;: &#39;primitive&#39;,
         &#39;value&#39;: &#39;0000-0002-0943-8725&#39;}}]},
     {&#39;typeName&#39;: &#39;datasetContact&#39;,
      &#39;multiple&#39;: True,
      &#39;typeClass&#39;: &#39;compound&#39;,
      &#39;value&#39;: [{&#39;datasetContactName&#39;: {&#39;typeName&#39;: &#39;datasetContactName&#39;,
         &#39;multiple&#39;: False,
         &#39;typeClass&#39;: &#39;primitive&#39;,
         &#39;value&#39;: &#39;Ripberger, Joseph&#39;},
        &#39;datasetContactAffiliation&#39;: {&#39;typeName&#39;: &#39;datasetContactAffiliation&#39;,
         &#39;multiple&#39;: False,
         &#39;typeClass&#39;: &#39;primitive&#39;,
         &#39;value&#39;: &#39;University of Oklahoma&#39;},
        &#39;datasetContactEmail&#39;: {&#39;typeName&#39;: &#39;datasetContactEmail&#39;,
         &#39;multiple&#39;: False,
         &#39;typeClass&#39;: &#39;primitive&#39;,
         &#39;value&#39;: &#39;jtr@ou.edu&#39;}}]},
     {&#39;typeName&#39;: &#39;dsDescription&#39;,
      &#39;multiple&#39;: True,
      &#39;typeClass&#39;: &#39;compound&#39;,
      &#39;value&#39;: [{&#39;dsDescriptionValue&#39;: {&#39;typeName&#39;: &#39;dsDescriptionValue&#39;,
         &#39;multiple&#39;: False,
         &#39;typeClass&#39;: &#39;primitive&#39;,
         &#39;value&#39;: &#39;The Severe Weather and Society Survey (WX) was designed and administered by the Center for Risk and Crisis Management (CRCM) at the University of Oklahoma. This is the second survey in the annual series (see Silva et al., 2017 for information on WX17). WX18 was fielded July 6-11, 2018 using an online questionnaire that was completed by 3,000 U.S. adults (age 18+) that were recruited from an Internet panel that matches the characteristics of the U.S. population as estimated in the U.S. Census. Following WX17, which was designed to establish baseline measures of the extent to which U.S. adults receive, understand, and respond to severe weather forecasts and warnings, WX18 was designed to continue and, in some cases, refine the measurement of these concepts. Additionally, WX18 measured public trust in the National Weather Service (NWS), extreme weather and climate risk perceptions, risk literacy, interpretations of probabilistic language, and response efficacy.&#39;}}]},
     {&#39;typeName&#39;: &#39;subject&#39;,
      &#39;multiple&#39;: True,
      &#39;typeClass&#39;: &#39;controlledVocabulary&#39;,
      &#39;value&#39;: [&#39;Social Sciences&#39;]},
     {&#39;typeName&#39;: &#39;depositor&#39;,
      &#39;multiple&#39;: False,
      &#39;typeClass&#39;: &#39;primitive&#39;,
      &#39;value&#39;: &#39;Ripberger, Joseph&#39;},
     {&#39;typeName&#39;: &#39;dateOfDeposit&#39;,
      &#39;multiple&#39;: False,
      &#39;typeClass&#39;: &#39;primitive&#39;,
      &#39;value&#39;: &#39;2020-01-13&#39;}]}},
  &#39;files&#39;: [{&#39;label&#39;: &#39;WX18_data_wtd.tab&#39;,
    &#39;restricted&#39;: False,
    &#39;version&#39;: 1,
    &#39;datasetVersionId&#39;: 210551,
    &#39;dataFile&#39;: {&#39;id&#39;: 3657710,
     &#39;persistentId&#39;: &#39;doi:10.7910/DVN/RHT4ON/7TRD5D&#39;,
     &#39;pidURL&#39;: &#39;https://doi.org/10.7910/DVN/RHT4ON/7TRD5D&#39;,
     &#39;filename&#39;: &#39;WX18_data_wtd.tab&#39;,
     &#39;contentType&#39;: &#39;text/tab-separated-values&#39;,
     &#39;friendlyType&#39;: &#39;Tab-Delimited&#39;,
     &#39;filesize&#39;: 2602546,
     &#39;storageIdentifier&#39;: &#39;s3://dvn-cloud:16f9f4bba61-8bbfafa227e7&#39;,
     &#39;originalFileFormat&#39;: &#39;text/csv&#39;,
     &#39;originalFormatLabel&#39;: &#39;Comma Separated Values&#39;,
     &#39;originalFileSize&#39;: 2609506,
     &#39;originalFileName&#39;: &#39;WX18_data_wtd.csv&#39;,
     &#39;UNF&#39;: &#39;UNF:6:Yyyznfcg+cNLP/7D2v9/wg==&#39;,
     &#39;rootDataFileId&#39;: -1,
     &#39;md5&#39;: &#39;c56b9b5ac4e603b085a00feabc4e6b04&#39;,
     &#39;checksum&#39;: {&#39;type&#39;: &#39;MD5&#39;, &#39;value&#39;: &#39;c56b9b5ac4e603b085a00feabc4e6b04&#39;},
     &#39;tabularData&#39;: True,
     &#39;creationDate&#39;: &#39;2020-01-13&#39;,
     &#39;publicationDate&#39;: &#39;2020-02-03&#39;,
     &#39;fileAccessRequest&#39;: False}},
   {&#39;label&#39;: &#39;WX18 Instrument.pdf&#39;,
    &#39;restricted&#39;: False,
    &#39;version&#39;: 1,
    &#39;datasetVersionId&#39;: 210551,
    &#39;dataFile&#39;: {&#39;id&#39;: 3657709,
     &#39;persistentId&#39;: &#39;doi:10.7910/DVN/RHT4ON/VBCEWA&#39;,
     &#39;pidURL&#39;: &#39;https://doi.org/10.7910/DVN/RHT4ON/VBCEWA&#39;,
     &#39;filename&#39;: &#39;WX18 Instrument.pdf&#39;,
     &#39;contentType&#39;: &#39;application/pdf&#39;,
     &#39;friendlyType&#39;: &#39;Adobe PDF&#39;,
     &#39;filesize&#39;: 234344,
     &#39;storageIdentifier&#39;: &#39;s3://dvn-cloud:16f9f4b7300-1ef8892476d5&#39;,
     &#39;rootDataFileId&#39;: -1,
     &#39;md5&#39;: &#39;4cc0791ef645b9c1440a005cf28ed7ce&#39;,
     &#39;checksum&#39;: {&#39;type&#39;: &#39;MD5&#39;, &#39;value&#39;: &#39;4cc0791ef645b9c1440a005cf28ed7ce&#39;},
     &#39;tabularData&#39;: False,
     &#39;creationDate&#39;: &#39;2020-01-13&#39;,
     &#39;publicationDate&#39;: &#39;2020-02-03&#39;,
     &#39;fileAccessRequest&#39;: False}},
   {&#39;label&#39;: &#39;WX18 Reference Report.pdf&#39;,
    &#39;restricted&#39;: False,
    &#39;version&#39;: 1,
    &#39;datasetVersionId&#39;: 210551,
    &#39;dataFile&#39;: {&#39;id&#39;: 3657708,
     &#39;persistentId&#39;: &#39;doi:10.7910/DVN/RHT4ON/PIZ2S6&#39;,
     &#39;pidURL&#39;: &#39;https://doi.org/10.7910/DVN/RHT4ON/PIZ2S6&#39;,
     &#39;filename&#39;: &#39;WX18 Reference Report.pdf&#39;,
     &#39;contentType&#39;: &#39;application/pdf&#39;,
     &#39;friendlyType&#39;: &#39;Adobe PDF&#39;,
     &#39;filesize&#39;: 437743,
     &#39;storageIdentifier&#39;: &#39;s3://dvn-cloud:16f9f4b6e56-79235ea20c8b&#39;,
     &#39;rootDataFileId&#39;: -1,
     &#39;md5&#39;: &#39;703b99829c8976ff33428ce2681afe9c&#39;,
     &#39;checksum&#39;: {&#39;type&#39;: &#39;MD5&#39;, &#39;value&#39;: &#39;703b99829c8976ff33428ce2681afe9c&#39;},
     &#39;tabularData&#39;: False,
     &#39;creationDate&#39;: &#39;2020-01-13&#39;,
     &#39;publicationDate&#39;: &#39;2020-02-03&#39;,
     &#39;fileAccessRequest&#39;: False}}]}}
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="step-1b-download-a-file">
<h2>Step 1b: Download a File<a class="headerlink" href="#step-1b-download-a-file" title="Link to this heading">#</a></h2>
<p>From the file-level metadata, we see that the dataset file (.tab) is accompanied by PDFs of the instrument and a reference report.</p>
<p>Let‚Äôs download the dataset file (.tab) for first year of the survey, WX18, which has a file_id of ‚Äú3657710‚Äù.  If you wanted to work with this data for real, you would also want to download the survey instrument and reference document to fully understand the data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># File ID for WxEM_Wave1.tab</span>
<span class="n">file_id</span> <span class="o">=</span> <span class="mi">3657710</span>

<span class="c1"># Download directly to memory</span>
<span class="n">file_url</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;https://dataverse.harvard.edu/api/access/datafile/</span><span class="si">{</span><span class="n">file_id</span><span class="si">}</span><span class="s2">?format=original&quot;</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">file_url</span><span class="p">)</span>

<span class="c1"># Load into pandas directly from memory, assuming comma-delimited content</span>
<span class="n">df_18</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">content</span><span class="p">),</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;ISO-8859-1&#39;</span><span class="p">,</span> <span class="n">engine</span><span class="o">=</span><span class="s1">&#39;python&#39;</span><span class="p">,</span> <span class="n">on_bad_lines</span><span class="o">=</span><span class="s1">&#39;skip&#39;</span><span class="p">)</span>
<span class="n">df_18</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>p_id</th>
      <th>age</th>
      <th>age_group</th>
      <th>gend</th>
      <th>hisp</th>
      <th>race</th>
      <th>state</th>
      <th>zip</th>
      <th>nws_region</th>
      <th>lat</th>
      <th>...</th>
      <th>begin_datetime</th>
      <th>end_datetime</th>
      <th>begin_date</th>
      <th>end_date</th>
      <th>begin_time</th>
      <th>end_time</th>
      <th>time_taken</th>
      <th>censusproportion</th>
      <th>surveyproportion</th>
      <th>weightfactor</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>EPO77VBNDHYXC5L4M3</td>
      <td>54</td>
      <td>4</td>
      <td>1</td>
      <td>0</td>
      <td>4</td>
      <td>Illinois</td>
      <td>60060</td>
      <td>Central Region</td>
      <td>42.200806</td>
      <td>...</td>
      <td>1530900028</td>
      <td>1530900853</td>
      <td>2018-07-06</td>
      <td>2018-07-06</td>
      <td>13:00:00</td>
      <td>13:14:00</td>
      <td>13</td>
      <td>0.001122</td>
      <td>0.003155</td>
      <td>0.355626</td>
    </tr>
    <tr>
      <th>1</th>
      <td>EPO77VDZDV5LMGD4M9</td>
      <td>66</td>
      <td>6</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>Maryland</td>
      <td>21921</td>
      <td>Eastern Region</td>
      <td>39.575394</td>
      <td>...</td>
      <td>1530900035</td>
      <td>1530901159</td>
      <td>2018-07-06</td>
      <td>2018-07-06</td>
      <td>13:00:00</td>
      <td>13:19:00</td>
      <td>18</td>
      <td>0.027792</td>
      <td>0.032461</td>
      <td>0.856166</td>
    </tr>
    <tr>
      <th>2</th>
      <td>EPO77VFD67MR5R44M7</td>
      <td>54</td>
      <td>4</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>New York</td>
      <td>14420</td>
      <td>Eastern Region</td>
      <td>43.250793</td>
      <td>...</td>
      <td>1530900046</td>
      <td>1530900927</td>
      <td>2018-07-06</td>
      <td>2018-07-06</td>
      <td>13:00:00</td>
      <td>13:15:00</td>
      <td>14</td>
      <td>0.030340</td>
      <td>0.057592</td>
      <td>0.526809</td>
    </tr>
    <tr>
      <th>3</th>
      <td>EPO77VFJ2CJKML44M9</td>
      <td>56</td>
      <td>5</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>Utah</td>
      <td>84097</td>
      <td>Western Region</td>
      <td>40.296799</td>
      <td>...</td>
      <td>1530900046</td>
      <td>1530900878</td>
      <td>2018-07-06</td>
      <td>2018-07-06</td>
      <td>13:00:00</td>
      <td>13:14:00</td>
      <td>13</td>
      <td>0.024319</td>
      <td>0.034826</td>
      <td>0.698300</td>
    </tr>
    <tr>
      <th>4</th>
      <td>EPO77VFD4CZHV2M4M0</td>
      <td>66</td>
      <td>6</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>California</td>
      <td>90620</td>
      <td>Western Region</td>
      <td>33.875504</td>
      <td>...</td>
      <td>1530900048</td>
      <td>1530900993</td>
      <td>2018-07-06</td>
      <td>2018-07-06</td>
      <td>13:00:00</td>
      <td>13:16:00</td>
      <td>15</td>
      <td>0.020574</td>
      <td>0.023217</td>
      <td>0.886161</td>
    </tr>
  </tbody>
</table>
<p>5 rows √ó 223 columns</p>
</div></div></div>
</div>
<section id="examine-the-dataset">
<h3>Examine the dataset<a class="headerlink" href="#examine-the-dataset" title="Link to this heading">#</a></h3>
<p>Pandas has a number of attributes that can be used to quickly examine characteristics of the dataset, things like size, shape, value distributions, basic stats, and missing values‚Ä¶anything you would normally do to check a dataset.  Below, I am just going to run a few of them.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># See basic shape of the data (rows, columns).  Each row represents a respondent.</span>

<span class="n">df_18</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(3000, 223)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># See quick summary statistics</span>

<span class="n">df_18</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>age_group</th>
      <th>gend</th>
      <th>hisp</th>
      <th>race</th>
      <th>zip</th>
      <th>lat</th>
      <th>lon</th>
      <th>long_years</th>
      <th>long_months</th>
      <th>...</th>
      <th>oft_twit</th>
      <th>oft_FB</th>
      <th>ign_instruct</th>
      <th>is_bluedot</th>
      <th>begin_datetime</th>
      <th>end_datetime</th>
      <th>time_taken</th>
      <th>censusproportion</th>
      <th>surveyproportion</th>
      <th>weightfactor</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>3000.000000</td>
      <td>3000.000000</td>
      <td>3000.000000</td>
      <td>3000.000000</td>
      <td>3000.000000</td>
      <td>3000.000000</td>
      <td>3000.000000</td>
      <td>3000.000000</td>
      <td>3000.000000</td>
      <td>3000.000000</td>
      <td>...</td>
      <td>2986.000000</td>
      <td>2995.000000</td>
      <td>2548.000000</td>
      <td>441.0</td>
      <td>3.000000e+03</td>
      <td>3.000000e+03</td>
      <td>3000.000000</td>
      <td>3000.000000</td>
      <td>3000.000000</td>
      <td>3000.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>46.848000</td>
      <td>3.672000</td>
      <td>0.486667</td>
      <td>0.163333</td>
      <td>1.515000</td>
      <td>50249.611000</td>
      <td>37.372934</td>
      <td>-91.077331</td>
      <td>26.346667</td>
      <td>21.698833</td>
      <td>...</td>
      <td>1.630610</td>
      <td>3.698831</td>
      <td>1.105573</td>
      <td>1.0</td>
      <td>1.531090e+09</td>
      <td>1.531092e+09</td>
      <td>34.997667</td>
      <td>0.017732</td>
      <td>0.022435</td>
      <td>0.935461</td>
    </tr>
    <tr>
      <th>std</th>
      <td>17.095701</td>
      <td>1.688401</td>
      <td>0.499906</td>
      <td>0.369731</td>
      <td>1.208137</td>
      <td>29599.090893</td>
      <td>5.247986</td>
      <td>15.748561</td>
      <td>288.801880</td>
      <td>677.357349</td>
      <td>...</td>
      <td>2.213069</td>
      <td>2.336457</td>
      <td>0.425254</td>
      <td>0.0</td>
      <td>1.045842e+05</td>
      <td>1.045703e+05</td>
      <td>236.781662</td>
      <td>0.010795</td>
      <td>0.016075</td>
      <td>0.707920</td>
    </tr>
    <tr>
      <th>min</th>
      <td>18.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>716.000000</td>
      <td>10.500000</td>
      <td>-145.612000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.0</td>
      <td>1.530900e+09</td>
      <td>1.530901e+09</td>
      <td>10.000000</td>
      <td>0.000016</td>
      <td>0.001047</td>
      <td>0.012780</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>32.000000</td>
      <td>2.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>27609.250000</td>
      <td>33.804703</td>
      <td>-97.821999</td>
      <td>4.000000</td>
      <td>1.000000</td>
      <td>...</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.0</td>
      <td>1.530985e+09</td>
      <td>1.530988e+09</td>
      <td>14.000000</td>
      <td>0.006619</td>
      <td>0.007886</td>
      <td>0.594824</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>47.000000</td>
      <td>4.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>46341.000000</td>
      <td>38.635750</td>
      <td>-85.886200</td>
      <td>10.000000</td>
      <td>4.000000</td>
      <td>...</td>
      <td>0.000000</td>
      <td>5.000000</td>
      <td>1.000000</td>
      <td>1.0</td>
      <td>1.531162e+09</td>
      <td>1.531164e+09</td>
      <td>19.000000</td>
      <td>0.020845</td>
      <td>0.022082</td>
      <td>0.784617</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>62.000000</td>
      <td>5.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>78043.500000</td>
      <td>41.134293</td>
      <td>-79.855425</td>
      <td>21.000000</td>
      <td>7.000000</td>
      <td>...</td>
      <td>4.000000</td>
      <td>6.000000</td>
      <td>1.000000</td>
      <td>1.0</td>
      <td>1.531171e+09</td>
      <td>1.531173e+09</td>
      <td>27.000000</td>
      <td>0.025745</td>
      <td>0.032541</td>
      <td>1.115311</td>
    </tr>
    <tr>
      <th>max</th>
      <td>87.000000</td>
      <td>6.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>7.000000</td>
      <td>99354.000000</td>
      <td>60.791702</td>
      <td>-60.750000</td>
      <td>14400.000000</td>
      <td>33180.000000</td>
      <td>...</td>
      <td>6.000000</td>
      <td>6.000000</td>
      <td>3.000000</td>
      <td>1.0</td>
      <td>1.531338e+09</td>
      <td>1.531339e+09</td>
      <td>9931.000000</td>
      <td>0.048527</td>
      <td>0.059686</td>
      <td>14.620821</td>
    </tr>
  </tbody>
</table>
<p>8 rows √ó 194 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get a quick count of missing data by column</span>

<span class="n">df_18</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>p_id                0
age                 0
age_group           0
gend                0
hisp                0
                   ..
end_time            0
time_taken          0
censusproportion    0
surveyproportion    0
weightfactor        0
Length: 223, dtype: int64
</pre></div>
</div>
</div>
</div>
<section id="variable-names">
<h4>Variable names<a class="headerlink" href="#variable-names" title="Link to this heading">#</a></h4>
<p>Next, we will list the columns to show all the variable names contained in the data.  To integrate with weather data, we are most interested in locating possible ways to join the data.  Typically, geographic variables are a good start.</p>
<h2><span style="color:red">Stop!  After we run the next cell, do you see any geographic variables that might be useful?</span></h2>
</section>
<section id="id1">
<h4><strong>&gt;&gt;Respond in the chat&lt;&lt;</strong><a class="headerlink" href="#id1" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># List all column names</span>
<span class="n">df_18</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;p_id&#39;,
 &#39;age&#39;,
 &#39;age_group&#39;,
 &#39;gend&#39;,
 &#39;hisp&#39;,
 &#39;race&#39;,
 &#39;state&#39;,
 &#39;zip&#39;,
 &#39;nws_region&#39;,
 &#39;lat&#39;,
 &#39;lon&#39;,
 &#39;long_years&#39;,
 &#39;long_months&#39;,
 &#39;last_state&#39;,
 &#39;now&#39;,
 &#39;rural&#39;,
 &#39;home&#39;,
 &#39;home_spec&#39;,
 &#39;rent&#39;,
 &#39;adults&#39;,
 &#39;children&#39;,
 &#39;follow&#39;,
 &#39;plan_around&#39;,
 &#39;und_weather&#39;,
 &#39;risk_wind&#39;,
 &#39;risk_rain&#39;,
 &#39;risk_heat&#39;,
 &#39;risk_drought&#39;,
 &#39;risk_cold&#39;,
 &#39;risk_snow&#39;,
 &#39;risk_tor&#39;,
 &#39;risk_flood&#39;,
 &#39;risk_hur&#39;,
 &#39;risk_fire&#39;,
 &#39;risk_tie&#39;,
 &#39;alert_und&#39;,
 &#39;tortrack&#39;,
 &#39;torwatch&#39;,
 &#39;torwarn&#39;,
 &#39;warn_prob_area&#39;,
 &#39;prob_dist&#39;,
 &#39;warn_prob_house&#39;,
 &#39;warn_cons&#39;,
 &#39;warn_time&#39;,
 &#39;warn_size&#39;,
 &#39;warn_time_minutes&#39;,
 &#39;warn_time_hours&#39;,
 &#39;watch_prob_area&#39;,
 &#39;watch_prob_house&#39;,
 &#39;watch_cons&#39;,
 &#39;watch_time&#39;,
 &#39;watch_size&#39;,
 &#39;watch_time_minutes&#39;,
 &#39;watch_time_hours&#39;,
 &#39;tor_watchwarn_und&#39;,
 &#39;tor_map_und&#39;,
 &#39;tor_radar_und&#39;,
 &#39;svr_hail&#39;,
 &#39;svr_wind&#39;,
 &#39;svr_lightning&#39;,
 &#39;svr_flood&#39;,
 &#39;svr_rain&#39;,
 &#39;svr_watchwarn_und&#39;,
 &#39;rec_all&#39;,
 &#39;rec_most&#39;,
 &#39;rec_soon&#39;,
 &#39;rec_miss&#39;,
 &#39;rec_area&#39;,
 &#39;rec_time&#39;,
 &#39;rec_sleep&#39;,
 &#39;rec_driving&#39;,
 &#39;rec_work&#39;,
 &#39;rec_store&#39;,
 &#39;rec_small_group&#39;,
 &#39;rec_large_group&#39;,
 &#39;rec_dif_sit&#39;,
 &#39;warn_hist&#39;,
 &#39;warn_when&#39;,
 &#39;warn_how_br_rad&#39;,
 &#39;warn_how_wx_rad&#39;,
 &#39;warn_how_tv&#39;,
 &#39;warn_how_siren&#39;,
 &#39;warn_how_int&#39;,
 &#39;warn_how_soc&#39;,
 &#39;warn_how_word&#39;,
 &#39;warn_how_phone&#39;,
 &#39;warn_how_oth&#39;,
 &#39;warn_how_spec&#39;,
 &#39;warn_how_dk&#39;,
 &#39;warn_timercv&#39;,
 &#39;warn_where&#39;,
 &#39;warn_where_specify&#39;,
 &#39;warn_iss&#39;,
 &#39;warn_sure&#39;,
 &#39;warn_tor&#39;,
 &#39;last_act&#39;,
 &#39;last_act_spec&#39;,
 &#39;last_act_satis&#39;,
 &#39;last_act_again&#39;,
 &#39;next_act_day&#39;,
 &#39;next_act_day_spec&#39;,
 &#39;next_act_night&#39;,
 &#39;next_act_night_spec&#39;,
 &#39;next_act_car&#39;,
 &#39;resp_ignore&#39;,
 &#39;resp_prot&#39;,
 &#39;resp_busy&#39;,
 &#39;resp_unsure&#39;,
 &#39;resp_sleep&#39;,
 &#39;resp_driving&#39;,
 &#39;resp_work&#39;,
 &#39;resp_store&#39;,
 &#39;resp_small_group&#39;,
 &#39;resp_large_group&#39;,
 &#39;resp_dif_sit&#39;,
 &#39;rand_morn&#39;,
 &#39;rec_morn&#39;,
 &#39;und_morn&#39;,
 &#39;resp_morn&#39;,
 &#39;rand_aft&#39;,
 &#39;rec_aft&#39;,
 &#39;und_aft&#39;,
 &#39;resp_aft&#39;,
 &#39;rand_eve&#39;,
 &#39;rec_eve&#39;,
 &#39;und_eve&#39;,
 &#39;resp_eve&#39;,
 &#39;short_torhit_time&#39;,
 &#39;short_torhit_resp&#39;,
 &#39;short_torhit_resp_confidence&#39;,
 &#39;short_torhit_resp_protect&#39;,
 &#39;long_torhit_time&#39;,
 &#39;long_torhit_resp&#39;,
 &#39;long_torhit_resp_confidence&#39;,
 &#39;long_torhit_resp_protect&#39;,
 &#39;tor_eff1&#39;,
 &#39;tor_eff2&#39;,
 &#39;tor_eff3&#39;,
 &#39;tor_eff4&#39;,
 &#39;tor_eff5&#39;,
 &#39;tor_eff6&#39;,
 &#39;tor_eff7&#39;,
 &#39;tor_eff8&#39;,
 &#39;nws_trust&#39;,
 &#39;lotv_trust&#39;,
 &#39;natv_trust&#39;,
 &#39;em_trust&#39;,
 &#39;fam_trust&#39;,
 &#39;wx_info1&#39;,
 &#39;wx_info2&#39;,
 &#39;wx_info3&#39;,
 &#39;wx_info4&#39;,
 &#39;wx_info5&#39;,
 &#39;wx_info6&#39;,
 &#39;wx_info7&#39;,
 &#39;wx_info8&#39;,
 &#39;wx_info_tie&#39;,
 &#39;prob_event&#39;,
 &#39;prob_word&#39;,
 &#39;whichphrases&#39;,
 &#39;ext_low&#39;,
 &#39;vry_low&#39;,
 &#39;vry_small&#39;,
 &#39;prty_low&#39;,
 &#39;small&#39;,
 &#39;low&#39;,
 &#39;remote&#39;,
 &#39;slight&#39;,
 &#39;medium&#39;,
 &#39;moderate&#39;,
 &#39;good&#39;,
 &#39;high&#39;,
 &#39;large&#39;,
 &#39;prty_high&#39;,
 &#39;vry_high&#39;,
 &#39;sig&#39;,
 &#39;ext_high&#39;,
 &#39;tor_exp_no&#39;,
 &#39;tor_exp_per&#39;,
 &#39;tor_exp_fam&#39;,
 &#39;tor_exp_neighbors&#39;,
 &#39;tor_exp_friends&#39;,
 &#39;svr_exp_no&#39;,
 &#39;svr_exp_per&#39;,
 &#39;svr_exp_fam&#39;,
 &#39;svr_exp_neighbors&#39;,
 &#39;svr_exp_friends&#39;,
 &#39;prep_plan&#39;,
 &#39;prep_kit&#39;,
 &#39;prep_water&#39;,
 &#39;prep_gen&#39;,
 &#39;prep_room&#39;,
 &#39;prep_shelt&#39;,
 &#39;transp_delay&#39;,
 &#39;transp_closures&#39;,
 &#39;transp_accidents&#39;,
 &#39;transp_qual&#39;,
 &#39;transp_spend&#39;,
 &#39;rel_1&#39;,
 &#39;rel_2&#39;,
 &#39;rel_3&#39;,
 &#39;rel_4&#39;,
 &#39;income&#39;,
 &#39;inc_50&#39;,
 &#39;inc_100&#39;,
 &#39;inc_150&#39;,
 &#39;inc_200&#39;,
 &#39;edu&#39;,
 &#39;oft_twit&#39;,
 &#39;oft_FB&#39;,
 &#39;ign_instruct&#39;,
 &#39;is_bluedot&#39;,
 &#39;comments&#39;,
 &#39;begin_datetime&#39;,
 &#39;end_datetime&#39;,
 &#39;begin_date&#39;,
 &#39;end_date&#39;,
 &#39;begin_time&#39;,
 &#39;end_time&#39;,
 &#39;time_taken&#39;,
 &#39;censusproportion&#39;,
 &#39;surveyproportion&#39;,
 &#39;weightfactor&#39;]
</pre></div>
</div>
</div>
</div>
<p>In this survey, some good possible variables are state, zip, and lat/lon. These are pretty straightforward, but I‚Äôm also curious about ‚Äúnws_region‚Äù? Does it contain WFOs? Let‚Äôs take a look!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Is nws_region usefl at all?</span>
<span class="n">df_18</span><span class="p">[</span><span class="s1">&#39;nws_region&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([&#39;Central Region&#39;, &#39;Eastern Region&#39;, &#39;Western Region&#39;,
       &#39;Southern Region&#39;, nan], dtype=object)
</pre></div>
</div>
</div>
</div>
<section id="unfortunately-nws-region-only-has-four-regions-nonetheless-it-might-be-useful-for-a-different-research-question">
<h5>Unfortunately, ‚Äúnws_region‚Äù only has four regions.  Nonetheless, it might be useful for a different research question.<a class="headerlink" href="#unfortunately-nws-region-only-has-four-regions-nonetheless-it-might-be-useful-for-a-different-research-question" title="Link to this heading">#</a></h5>
<div style="background-color:#fb1e1eff; color:white; padding:20px; border-radius:10px; text-align:center; font-size:28px; font-weight:bold;">
  Stop!  Take a break! 
</div><div style="background-color:#0069afff; color:white; padding:20px; border-radius:10px; text-align:center; font-size:28px; font-weight:bold;">
  Step 2
</div>
</section>
</section>
</section>
</section>
<section id="step-2-use-an-api-to-download-weather-data">
<h2>Step 2: Use an API to download weather data<a class="headerlink" href="#step-2-use-an-api-to-download-weather-data" title="Link to this heading">#</a></h2>
<p>First, we will demonstrate how the Iowa Mesonet API can be used to collect weather alerts for each survey respondent.  Since calling an API can be slow and depends on internet access, we have already pre-downloaded the weather data needed for this analysis.</p>
<p>Next, we will take this pre-loaded weather data and merge it with the survey responses so that each person‚Äôs record includes both their answers and the relevant weather alerts.</p>
<section id="iowa-mesonet-api-do-not-run-at-this-time">
<h3>Iowa Mesonet API - DO NOT RUN AT THIS TIME<a class="headerlink" href="#iowa-mesonet-api-do-not-run-at-this-time" title="Link to this heading">#</a></h3>
<p>The code below is doing alot of work, going through the survey data <strong>one person at a time</strong> and asking the Iowa Mesonet API:</p>
<p>‚ÄúGiven this person‚Äôs location and survey date, what watches, warnings, or advisories (WWAs) were active in the few days leading up to that date?‚Äù</p>
<p>Here‚Äôs what happens step by step:</p>
<ol class="arabic simple">
<li><p><strong>Make sure the date is in the right format.</strong><br />
The <code class="docutils literal notranslate"><span class="pre">begin_date</span></code> column is converted into a standard date format so the computer can work with it (it‚Äôs a precaution).</p></li>
<li><p><strong>Prepare a place to store the results.</strong><br />
A new column called <code class="docutils literal notranslate"><span class="pre">wwa_names</span></code> is added to the survey data. This will eventually hold a <em>list</em> of weather alerts for each person.  In Python, you can think of a list as a flexible container that holds a collection of items.</p></li>
<li><p><strong>Go through each respondent one by one.</strong><br />
For each person, we:</p>
<ul class="simple">
<li><p>Look up their latitude, longitude, and survey date.</p></li>
<li><p>Define a <strong>3-day window</strong> before their survey date (so we catch recent alerts).</p></li>
<li><p>Build a request to the Iowa Mesonet API using their location and dates.</p></li>
</ul>
</li>
<li><p><strong>Ask the API for weather alerts.</strong></p>
<ul class="simple">
<li><p>If the API responds successfully, we pull out the names of any alerts and save them in that person‚Äôs row.</p></li>
<li><p>If something goes wrong (bad connection, no data, etc.), we save an <em>empty list</em> for that person.</p></li>
<li><p>The API call will continue until we run out of survey respondents.</p></li>
</ul>
</li>
</ol>
<p>The resulting dataset (<code class="docutils literal notranslate"><span class="pre">df_18</span></code>) has a new column called <code class="docutils literal notranslate"><span class="pre">wwa_names</span></code> that tells us which WWAs (if any) each respondent experienced around the time of their survey.</p>
<p><strong>Analogy:</strong> This is like calling a weather hotline for each person‚Äôs hometown and writing down any recent alerts next to their name in the survey spreadsheet.</p>
<p>Please note the API Endpoint (Rest-like) and the structure of the request for those variables:</p>
<p><a class="reference external" href="https://mesonet.agron.iastate.edu/vtec/json.php?lon=%7Blon%7D&amp;amp;lat=%7Blat%7D&amp;amp;sdate=%7Bstart%7D&amp;amp;edate=%7Bend%7D">https://mesonet.agron.iastate.edu/vtec/json.php?lon={lon}&amp;lat={lat}&amp;sdate={start}&amp;edate={end}</a></p>
<p>Remember, you can always check the API documentation for guidance: the <a class="reference external" href="https://mesonet.agron.iastate.edu/api/">Iowa Mesonet API Guide</a>.</p>
<p><strong>Note:  We will not run this API call during the webinar because it takes about 20-30 minutes to download the data. If you want to try this after the webinar, just remove the first line (‚Äò‚Äô‚Äôpython) and run the cell.</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="s1">&#39;&#39;&#39;python</span>

<span class="s1"># Make sure begin_date is in datetime format</span>
<span class="s1">df_18[&#39;begin_date&#39;] = pd.to_datetime(df_18[&#39;begin_date&#39;])</span>

<span class="s1"># New column to store list of WWA names</span>
<span class="s1">df_18[&#39;wwa_names&#39;] = None</span>

<span class="s1"># Loop through each respondent</span>
<span class="s1">for idx, row in tqdm(df_18.iterrows(), total=len(df_18)):</span>
<span class="s1">    lat = row[&#39;lat&#39;]</span>
<span class="s1">    lon = row[&#39;lon&#39;]</span>
<span class="s1">    end_date = row[&#39;begin_date&#39;]</span>
<span class="s1">    start_date = end_date - timedelta(days=3)</span>

<span class="s1">    # Build API URL with small buffer</span>
<span class="s1">    url = (</span>
<span class="s1">        f&quot;https://mesonet.agron.iastate.edu/json/vtec_events_bypoint.py&quot;</span>
<span class="s1">        f&quot;?lat=</span><span class="si">{lat}</span><span class="s1">&amp;lon=</span><span class="si">{lon}</span><span class="s1">&quot;</span>
<span class="s1">        f&quot;&amp;sdate={start_date.strftime(&#39;%Y-%m-</span><span class="si">%d</span><span class="s1">&#39;)}&amp;edate={end_date.strftime(&#39;%Y-%m-</span><span class="si">%d</span><span class="s1">&#39;)}&quot;</span>
<span class="s1">        f&quot;&amp;buffer=0.1&quot;</span>
<span class="s1">    )</span>

<span class="s1">    try:</span>
<span class="s1">        response = requests.get(url)</span>
<span class="s1">        if response.status_code == 200:</span>
<span class="s1">            data = response.json()</span>
<span class="s1">            names = [event[&#39;name&#39;] for event in data.get(&#39;events&#39;, [])]</span>
<span class="s1">            df_18.at[idx, &#39;wwa_names&#39;] = names</span>
<span class="s1">        else:</span>
<span class="s1">            df_18.at[idx, &#39;wwa_names&#39;] = []</span>
<span class="s1">    except Exception as e:</span>
<span class="s1">        print(f&quot;Failed for idx=</span><span class="si">{idx}</span><span class="s1">, lat=</span><span class="si">{lat}</span><span class="s1">, lon=</span><span class="si">{lon}</span><span class="s1">: </span><span class="si">{e}</span><span class="s1">&quot;)</span>
<span class="s1">        df_18.at[idx, &#39;wwa_names&#39;] = []</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span>  <span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">15</span><span class="p">],</span> <span class="n">line</span> <span class="mi">1</span>
    <span class="s1">&#39;&#39;&#39;python</span>
<span class="s1">    ^</span>
<span class="ne">SyntaxError</span>: incomplete input
</pre></div>
</div>
</div>
</div>
<div style="background-color:#004b98ff; color:white; padding:20px; border-radius:10px; text-align:center; font-size:28px; font-weight:bold;">
  Step 3
</div>
</section>
<section id="step-3-joining-the-survey-data-with-weather-alerts">
<h3>Step 3 - Joining the Survey Data with Weather Alerts<a class="headerlink" href="#step-3-joining-the-survey-data-with-weather-alerts" title="Link to this heading">#</a></h3>
<p>Prior to the webinar, the data we needed was downloaded in a csv file and stored in Github.  This dataset (‚Äòwwa_by_pid‚Äô) includes the respondent identifier (‚Äòp_id‚Äô) and a column with watches, warnings, and advisories (‚Äòwwa_names‚Äô) in a list.  At this point, we have two different tables of data that we need to merge:</p>
<ul class="simple">
<li><p><strong>Survey data</strong> (df_18): this has all the survey responses, including their p_id (a unique identifier for each person).</p></li>
<li><p><strong>Weather alerts data</strong> (lk): this has just two columns ‚Äî the same p_id, and the list of watches, warnings, or advisories (wwa_names) that each person experienced.</p></li>
</ul>
<p>We‚Äôre going to merge both tables on p_id, which is basically doing the following:</p>
<p><strong>‚ÄúFor each person (p_id) in the survey data, look up their matching p_id in the weather file and bring in the weather alerts column (wwa_names).‚Äù</strong></p>
<section id="if-you-ran-the-api-call-in-step-2-you-should-skip-the-next-two-cells">
<h4>If you ran the API call in Step 2, you should skip the next two cells.<a class="headerlink" href="#if-you-ran-the-api-call-in-step-2-you-should-skip-the-next-two-cells" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># If you have run the API, you should skip this cell</span>

<span class="c1"># Read in the saved lookup file</span>
<span class="n">lk</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/wwa_by_pid.csv&quot;</span><span class="p">)</span>

<span class="c1"># Merge with the original df_18 on &#39;p_id&#39;</span>
<span class="n">df_18</span> <span class="o">=</span> <span class="n">df_18</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">lk</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s2">&quot;p_id&quot;</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># We use `ast` to convert the `wwa_names` column from text back into real Python lists so we can work with them.  </span>
<span class="n">df_18</span><span class="p">[</span><span class="s1">&#39;wwa_names&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_18</span><span class="p">[</span><span class="s1">&#39;wwa_names&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
    <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">ast</span><span class="o">.</span><span class="n">literal_eval</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">x</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="if-you-ran-the-api-call-in-step-2-you-can-resume-here">
<h4>If you ran the API call in Step 2, you can resume here.<a class="headerlink" href="#if-you-ran-the-api-call-in-step-2-you-can-resume-here" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Let&#39;s take a quick look at the new, combined dataset</span>
<span class="n">df_18</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># We can subset the dataframe to focus only on the variables we want to see.  We use the attribute &quot;dropna&quot; to make sure that there are no rows that are empty (i.e., we didn&#39;t screw something up).</span>
<span class="n">df_18</span><span class="p">[[</span><span class="s1">&#39;p_id&#39;</span><span class="p">,</span><span class="s1">&#39;lat&#39;</span><span class="p">,</span> <span class="s1">&#39;lon&#39;</span><span class="p">,</span> <span class="s1">&#39;begin_date&#39;</span><span class="p">,</span> <span class="s1">&#39;wwa_names&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#let&#39;s make sure we have the same number of row that we started with.  It should be 3,000</span>
<span class="n">df_18</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#how many respondents experienced watches/warnings/advisories?</span>
<span class="n">df_18</span><span class="p">[</span><span class="s1">&#39;wwa_names&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#who received more than two?</span>
<span class="n">df_18</span><span class="p">[</span><span class="n">df_18</span><span class="p">[</span><span class="s1">&#39;wwa_names&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">)</span>
<span class="p">][[</span><span class="s1">&#39;p_id&#39;</span><span class="p">,</span><span class="s1">&#39;lat&#39;</span><span class="p">,</span> <span class="s1">&#39;lon&#39;</span><span class="p">,</span> <span class="s1">&#39;begin_date&#39;</span><span class="p">,</span> <span class="s1">&#39;wwa_names&#39;</span><span class="p">]]</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="step-3a-exporting-the-data-for-use-outside-jupyter">
<h3>Step 3a: Exporting the Data for Use Outside Jupyter<a class="headerlink" href="#step-3a-exporting-the-data-for-use-outside-jupyter" title="Link to this heading">#</a></h3>
<p>Now that we have a merged dataframe (df_18) containing both survey responses and weather alerts, we can save and download it in different formats for use in other tools and workflows. Jupyter is excellent for exploring, cleaning, and manipulating data, but once you‚Äôve shaped the dataset you want, you may prefer to bring it back into your regular workflow ‚Äî whether that‚Äôs statistical software, spreadsheets, or visualization platforms. We won‚Äôt actually run the save commands here, but I‚Äôll provide the code snippets so you can see how it‚Äôs done.</p>
<p><strong>CSV (general use‚ÄìExcel, R, SAS, SPSS, STATA)</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#df_18.to_csv(&quot;survey_weather.csv&quot;, index=False)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Parquet (general use‚Äìfor larger datasets)</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#df_18.to_parquet(&quot;survey_weather.parquet&quot;)</span>
</pre></div>
</div>
</div>
</div>
<div style="background-color:#003087ff; color:white; padding:20px; border-radius:10px; text-align:center; font-size:28px; font-weight:bold;">
  Step 4
</div>
</section>
<section id="step-4-exploring-the-combined-dataset">
<h3>Step 4: Exploring the Combined Dataset<a class="headerlink" href="#step-4-exploring-the-combined-dataset" title="Link to this heading">#</a></h3>
<p>After you download the new dataset, you could easily just jump back into your regular workflow.  But let‚Äôs say we want to continue in Jupyter to quickly visualize and analyze the data to examine the data for any insights.  Below we will look at the following:</p>
<ul class="simple">
<li><p><em><strong>Quick Visualizations</strong></em></p></li>
<li><p><em><strong>Visualizing WWAs by Survey Responses</strong></em></p></li>
<li><p><em><strong>Quick Statistical Analyses</strong></em></p></li>
<li><p><em><strong>A Bit More Involved Analysis</strong></em></p></li>
</ul>
<section id="step-4a-quick-visualizations">
<h4>Step 4a: Quick visualizations<a class="headerlink" href="#step-4a-quick-visualizations" title="Link to this heading">#</a></h4>
<p>In this step, we will go over three basic visualizations:</p>
<ol class="arabic simple">
<li><p>A geomap of survey respondents by number of watches and warnings 3 days prior to the survey.</p></li>
<li><p>A bar chart showing frequency of types of watches and warnings.</p></li>
<li><p>A line graph showing frequency of types of watches and warning over time.</p></li>
</ol>
<p>Jupyter (and Python) provide access to a wide range of powerful visualization libraries ‚Äî from simple plotting with <strong>matplotlib</strong> and <strong>seaborn</strong> to interactive mapping with <strong>folium</strong> or <strong>plotly</strong> ‚Äî giving you many options for exploring and presenting your data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Step 1: Ensure lat/lon are float (just in case)</span>
<span class="n">df_18</span><span class="p">[</span><span class="s1">&#39;lat&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_numeric</span><span class="p">(</span><span class="n">df_18</span><span class="p">[</span><span class="s1">&#39;lat&#39;</span><span class="p">],</span> <span class="n">errors</span><span class="o">=</span><span class="s1">&#39;coerce&#39;</span><span class="p">)</span>
<span class="n">df_18</span><span class="p">[</span><span class="s1">&#39;lon&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_numeric</span><span class="p">(</span><span class="n">df_18</span><span class="p">[</span><span class="s1">&#39;lon&#39;</span><span class="p">],</span> <span class="n">errors</span><span class="o">=</span><span class="s1">&#39;coerce&#39;</span><span class="p">)</span>

<span class="c1"># Step 2: Create geometry from lat/lon</span>
<span class="n">geometry</span> <span class="o">=</span> <span class="p">[</span><span class="n">Point</span><span class="p">(</span><span class="n">xy</span><span class="p">)</span> <span class="k">for</span> <span class="n">xy</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">df_18</span><span class="p">[</span><span class="s1">&#39;lon&#39;</span><span class="p">],</span> <span class="n">df_18</span><span class="p">[</span><span class="s1">&#39;lat&#39;</span><span class="p">])]</span>
<span class="n">gdf_18</span> <span class="o">=</span> <span class="n">gpd</span><span class="o">.</span><span class="n">GeoDataFrame</span><span class="p">(</span><span class="n">df_18</span><span class="p">,</span> <span class="n">geometry</span><span class="o">=</span><span class="n">geometry</span><span class="p">,</span> <span class="n">crs</span><span class="o">=</span><span class="s2">&quot;EPSG:4326&quot;</span><span class="p">)</span>

<span class="c1"># Step 3: Count WWAs</span>
<span class="n">gdf_18</span><span class="p">[</span><span class="s1">&#39;wwa_count&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">gdf_18</span><span class="p">[</span><span class="s1">&#39;wwa_names&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>

<span class="c1"># Step 4: Plot</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">gdf_18</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">column</span><span class="o">=</span><span class="s1">&#39;wwa_count&#39;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;OrRd&#39;</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Survey Respondents by Number of WWAs (3 Days Prior)&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="s1">&#39;&#39;&#39; python</span>

<span class="s1"># Flatten and count</span>
<span class="s1">all_names = df_18[&#39;wwa_names&#39;].dropna().explode()</span>
<span class="s1">top_names = Counter(all_names).most_common(10)</span>

<span class="s1"># Plot</span>
<span class="s1">names, counts = zip(*top_names)</span>
<span class="s1">plt.figure(figsize=(10, 5))</span>
<span class="s1">plt.barh(names[::-1], counts[::-1])</span>
<span class="s1">plt.title(&quot;Top 10 Most Frequent WWAs&quot;)</span>
<span class="s1">plt.xlabel(&quot;Number of Respondents Exposed&quot;)</span>
<span class="s1">plt.tight_layout()</span>
<span class="s1">plt.show()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="s1">&#39;&#39;&#39; python</span>

<span class="s1"># Count WWAs per date</span>
<span class="s1">timeline = (</span>
<span class="s1">    df_18[[&#39;begin_date&#39;, &#39;wwa_names&#39;]]</span>
<span class="s1">    .dropna()</span>
<span class="s1">    .assign(wwa_count=lambda df: df[&#39;wwa_names&#39;].apply(len))</span>
<span class="s1">    .groupby(&#39;begin_date&#39;)[&#39;wwa_count&#39;]</span>
<span class="s1">    .sum()</span>
<span class="s1">)</span>

<span class="s1"># Plot</span>
<span class="s1">timeline.plot(marker=&#39;o&#39;, figsize=(10, 4), title=&#39;Total WWAs by Survey Date&#39;)</span>
<span class="s1">plt.ylabel(&#39;Total Warnings/Watch Events&#39;)</span>
<span class="s1">plt.xlabel(&#39;Survey Date&#39;)</span>
<span class="s1">plt.grid(True)</span>
<span class="s1">plt.tight_layout()</span>
<span class="s1">plt.show()</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="step-4b-visualizing-wwwas-by-survey-reponses">
<h3>Step 4b: Visualizing WWWAs by Survey Reponses<a class="headerlink" href="#step-4b-visualizing-wwwas-by-survey-reponses" title="Link to this heading">#</a></h3>
<p>For a next step, we might do some quick analyses/visualizations of WWAs by survey response.</p>
<p>Let‚Äôs say we want to examine how the presence of recent NWS advisories (3 days prior to taking the survey) correlates with survey respondents‚Äô perceived risk of that hazard.  Again, we‚Äôre going to focus on flood-related WWAs.  How can we do that?</p>
<p>Step 1.  Create two groups of respondents, those experienced a WWA prior to the survey and those who did not.
Step 2.  Extract risk perception scores for a hazard (For risk_flood: 1-No risk, 2-Low Risk‚Ä¶..5-Extreme risk)
Step 3.  Create comparative visualizations</p>
<p>For the first two steps, we have created a function <strong>(def)</strong> to carry out those tasks.  We could easily do this without creating a function but it would take several steps to do so.  Here we get it done in one cell.  When you run the cell, you will notice that there are no results</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># --- Prep: robust WWA exposure + ordered risk labels ---</span>

<span class="c1"># 1) robust flood_wwa_exposure (handles NaN/non-lists)</span>
<span class="n">flood_wwa_keywords</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Flood Advisory&#39;</span><span class="p">,</span> <span class="s1">&#39;Flood Warning&#39;</span><span class="p">,</span> <span class="s1">&#39;Flash Flood Warning&#39;</span><span class="p">,</span> <span class="s1">&#39;Flash Flood Watch&#39;</span><span class="p">,</span> <span class="s1">&#39;Flood Watch&#39;</span><span class="p">]</span>

<span class="k">def</span><span class="w"> </span><span class="nf">has_flood_wwa</span><span class="p">(</span><span class="n">wwas</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">wwas</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">,</span> <span class="nb">set</span><span class="p">)):</span>
        <span class="k">return</span> <span class="nb">any</span><span class="p">(</span><span class="n">k</span> <span class="ow">in</span> <span class="n">wwas</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">flood_wwa_keywords</span><span class="p">)</span>
    <span class="k">return</span> <span class="kc">False</span>

<span class="n">df_18</span><span class="p">[</span><span class="s1">&#39;flood_wwa_exposure&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_18</span><span class="p">[</span><span class="s1">&#39;wwa_names&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">has_flood_wwa</span><span class="p">)</span>

<span class="c1"># 2) numeric -&gt; labeled flood risk (ordered categorical)</span>
<span class="n">label_map</span> <span class="o">=</span> <span class="p">{</span><span class="mi">1</span><span class="p">:</span> <span class="s1">&#39;No risk&#39;</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span> <span class="s1">&#39;Low risk&#39;</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span> <span class="s1">&#39;Moderate risk&#39;</span><span class="p">,</span> <span class="mi">4</span><span class="p">:</span> <span class="s1">&#39;High risk&#39;</span><span class="p">,</span> <span class="mi">5</span><span class="p">:</span> <span class="s1">&#39;Extreme risk&#39;</span><span class="p">}</span>
<span class="n">ordered_risk_labels</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">label_map</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>

<span class="c1"># Coerce to numeric, map to labels, and set categorical order</span>
<span class="n">df_18</span><span class="p">[</span><span class="s1">&#39;risk_flood_num&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_numeric</span><span class="p">(</span><span class="n">df_18</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;risk_flood&#39;</span><span class="p">),</span> <span class="n">errors</span><span class="o">=</span><span class="s1">&#39;coerce&#39;</span><span class="p">)</span>
<span class="n">df_18</span><span class="p">[</span><span class="s1">&#39;risk_flood_label&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span>
    <span class="n">df_18</span><span class="p">[</span><span class="s1">&#39;risk_flood_num&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">label_map</span><span class="p">),</span>
    <span class="n">categories</span><span class="o">=</span><span class="n">ordered_risk_labels</span><span class="p">,</span>
    <span class="n">ordered</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>

<span class="c1">#Let&#39;s take a look at what we just did</span>

<span class="n">df_18</span><span class="p">[[</span><span class="s1">&#39;wwa_names&#39;</span><span class="p">,</span> <span class="s1">&#39;flood_wwa_exposure&#39;</span><span class="p">,</span> <span class="s1">&#39;risk_flood_num&#39;</span><span class="p">,</span> <span class="s1">&#39;risk_flood_label&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">df_18</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="s1">&#39;risk_flood_label&#39;</span><span class="p">,</span>
    <span class="n">hue</span><span class="o">=</span><span class="s1">&#39;flood_wwa_exposure&#39;</span><span class="p">,</span>
    <span class="n">order</span><span class="o">=</span><span class="n">ordered_risk_labels</span><span class="p">,</span>
    <span class="n">hue_order</span><span class="o">=</span><span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">]</span>
<span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Perceived Flood Risk&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Number of Respondents&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Perceived Flood Risk by Exposure to Flood-Related WWAs&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;WWA Exposure&quot;</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;No&quot;</span><span class="p">,</span> <span class="s2">&quot;Yes&quot;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># crosstab -&gt; proportions by exposure</span>
<span class="n">crosstab</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">crosstab</span><span class="p">(</span>
    <span class="n">df_18</span><span class="p">[</span><span class="s1">&#39;flood_wwa_exposure&#39;</span><span class="p">],</span>
    <span class="n">df_18</span><span class="p">[</span><span class="s1">&#39;risk_flood_label&#39;</span><span class="p">],</span>
    <span class="n">normalize</span><span class="o">=</span><span class="s1">&#39;index&#39;</span>
<span class="p">)</span>

<span class="c1"># ensure consistent order of rows/columns even if some levels are missing</span>
<span class="n">crosstab</span> <span class="o">=</span> <span class="n">crosstab</span><span class="o">.</span><span class="n">reindex</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">],</span> <span class="n">columns</span><span class="o">=</span><span class="n">ordered_risk_labels</span><span class="p">)</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">crosstab</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">kind</span><span class="o">=</span><span class="s1">&#39;bar&#39;</span><span class="p">,</span>
    <span class="n">stacked</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Flood Risk Perception by WWA Exposure (Proportions)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Perceived Flood Risk&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Proportion of Respondents&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;Exposed to Flood WWA&#39;</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;No&#39;</span><span class="p">,</span> <span class="s1">&#39;Yes&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Violin plots are interesting, let&#39;s take a look.</span>
<span class="n">sns</span><span class="o">.</span><span class="n">violinplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df_18</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;flood_wwa_exposure&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;risk_flood&#39;</span><span class="p">,</span> <span class="n">inner</span><span class="o">=</span><span class="s1">&#39;quartile&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;No WWA Exposure&#39;</span><span class="p">,</span> <span class="s1">&#39;WWA Exposure&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Exposure to Flood WWA&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Perceived Flood Risk (1-5)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Distribution of Flood Risk Perception by WWA Exposure&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="step-4c-quick-statistical-analyses">
<h2>Step 4C: Quick Statistical Analyses<a class="headerlink" href="#step-4c-quick-statistical-analyses" title="Link to this heading">#</a></h2>
<p>We‚Äôre not limited to visualizations, we can explore a number of statistical procedures to begin to test our question of whether exposure to warnings and watches has an impact on survey responses.  For this tutorial, we will quickly conduct the following:</p>
<ol class="arabic simple">
<li><p>Chi-Square: To evaluate whether exposure to flood-related warnings and watches and perceived flood risk categories are independent, with the p-value indicating if the observed relationship is statistically significant.</p></li>
<li><p>Logistic Regression: To evaluate whether exposure to flood-related warnings and watches increases the odds of respondents reporting high or extreme flood risk compared to lower risk levels.</p></li>
<li><p>Ordinal Logistic Regression: To evaluate whether exposure to flood-related warnings and watches shifts respondents toward higher categories of perceived flood risk.</p></li>
</ol>
<section id="chi-square">
<h3>1. Chi-Square<a class="headerlink" href="#chi-square" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Let&#39;s create a contingency table</span>

<span class="n">contingency</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">crosstab</span><span class="p">(</span><span class="n">df_18</span><span class="p">[</span><span class="s1">&#39;flood_wwa_exposure&#39;</span><span class="p">],</span> <span class="n">df_18</span><span class="p">[</span><span class="s1">&#39;risk_flood_label&#39;</span><span class="p">])</span>
<span class="n">contingency</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#let&#39;s test it</span>

<span class="n">chi2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">dof</span><span class="p">,</span> <span class="n">expected</span> <span class="o">=</span> <span class="n">chi2_contingency</span><span class="p">(</span><span class="n">contingency</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Chi-square test&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Chi2 = </span><span class="si">{</span><span class="n">chi2</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">, df = </span><span class="si">{</span><span class="n">dof</span><span class="si">}</span><span class="s2">, p = </span><span class="si">{</span><span class="n">p</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>This suggests that the distribution of flood risk perceptions is not independent of WWA exposure ‚Äî in other words, people who were exposed to flood-related WWAs responded differently (in terms of risk levels) than those who were not exposed.</p>
</section>
<section id="logistic-regression">
<h3>2. Logistic Regression<a class="headerlink" href="#logistic-regression" title="Link to this heading">#</a></h3>
<p>We‚Äôre going to fit a logistic regression model to test whether exposure to a flood watch/warning/advisory (WWA) predicts whether a survey respondent reports being at ‚Äúhigh‚Äù or ‚Äúextreme‚Äù flood risk.</p>
<p>In short: the regression asks, ‚ÄúHow much more likely are people to report high or extreme flood risk if they were exposed to a flood-related watch or warning?‚Äù</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="s1">&#39;&#39;&#39;python</span>

<span class="s1"># Binary outcome: high risk (‚â•4) vs. lower</span>
<span class="s1">df_18[&#39;high_risk&#39;] = df_18[&#39;risk_flood_num&#39;] &gt;= 4</span>

<span class="s1"># Predictor: WWA exposure (cast to int)</span>
<span class="s1">X = sm.add_constant(df_18[&#39;flood_wwa_exposure&#39;].astype(int))</span>
<span class="s1">y = df_18[&#39;high_risk&#39;].astype(int)</span>

<span class="s1">logit_model = sm.Logit(y, X).fit()</span>
<span class="s1">print(logit_model.summary())</span>
</pre></div>
</div>
</div>
</div>
<p>This suggests that respondents exposed to a flood WWA had significantly higher odds (about 39% greater, exp(0.3326) ‚âà 1.39) of reporting high or extreme flood risk compared to those not exposed, though the overall model explains only a small share of variation in responses.</p>
</section>
<section id="ordinal-logistic-regression">
<h3>3. Ordinal Logistic Regression<a class="headerlink" href="#ordinal-logistic-regression" title="Link to this heading">#</a></h3>
<p>The previous regression was a binary logistic regression, and the outcome was simplified into two categories: high risk (4‚Äì5) vs. not high (1‚Äì3).  The model only asks: ‚ÄúDoes exposure change the odds of being high risk or not?‚Äù</p>
<p>With this model, we use the full ordered scale (1-5), which accounts for the fact that reporting risk = 5 is ‚Äúhigher‚Äù than risk = 4, which is higher than risk = 3, etc.</p>
<p>Instead of focusing on a single cutoff, the model estimates the effect of exposure across all possible thresholds in the risk scale.  And you get cut-points plus one slope coefficient. The slope tells you whether exposure consistently increases the likelihood of reporting any higher category of risk.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="s1">&#39;&#39;&#39;python</span>

<span class="s1"># Drop NaNs to avoid issues</span>
<span class="s1">df_ord = df_18.dropna(subset=[&#39;risk_flood_num&#39;, &#39;flood_wwa_exposure&#39;])</span>

<span class="s1"># Predictor must be numeric (int)</span>
<span class="s1">X = df_ord[[&#39;flood_wwa_exposure&#39;]].astype(int)</span>

<span class="s1"># Outcome is ordered categories (numeric risk levels already ordered 1‚Äì5)</span>
<span class="s1">y = df_ord[&#39;risk_flood_num&#39;]</span>

<span class="s1"># Fit ordinal logistic regression</span>
<span class="s1">mod = OrderedModel(y, X, distr=&#39;logit&#39;)</span>
<span class="s1">res = mod.fit(method=&#39;bfgs&#39;)</span>

<span class="s1">print(res.summary())</span>
</pre></div>
</div>
</div>
</div>
<p>This suggests that respondents exposed to flood-related warnings and watches had a significantly higher likelihood of placing themselves in higher flood risk perception categories (coef = 0.296, p &lt; 0.001), indicating a consistent upward shift in perceived risk.</p>
</section>
</section>
<section id="a-bit-more-involved-did-wwas-really-affect-risk-perception">
<h2>A Bit More Involved - Did WWAs <em>Really</em> Affect Risk Perception?<a class="headerlink" href="#a-bit-more-involved-did-wwas-really-affect-risk-perception" title="Link to this heading">#</a></h2>
<p>So it appears that exposure to watches and warnings has a statistically significant impact on survey responses.  But by how much (substantive significance)? To suggest an answer, we might look at the <strong>predicted probabilities</strong> of survey responses.  This shows us how much exposure to a WWA changes the likelihood of a respondent reporting ‚ÄúHigh‚Äù or ‚ÄúExtreme‚Äù flood risk.</p>
<p>To do this, the code below creates two simple scenarios: one where a person had no flood alert (0) and one where they did (1).  It then uses a statistical model (ordinal logist model with a logit link function) to predict the probability of each risk category under those two scenarios.  The results are labeled clearly as ‚ÄúNo Exposure‚Äù and ‚ÄúExposure,‚Äù giving us a side-by-side view.</p>
<p><strong>Analogy:</strong> It‚Äôs like asking, ‚ÄúWhat would the risk look like if nobody had a flood alert?‚Äù and then,  ‚ÄúWhat would the risk look like if everyone had a flood alert?‚Äù ‚Äî and comparing the two answers side by side.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Make two scenarios: no exposure (0) and exposure (1)</span>
<span class="n">scenarios</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s1">&#39;flood_wwa_exposure&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="p">})</span>

<span class="c1"># Predict probabilities for each risk category</span>
<span class="n">pred_probs</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">scenarios</span><span class="p">)</span>

<span class="c1"># Attach labels</span>
<span class="n">pred_probs</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;No Exposure&#39;</span><span class="p">,</span> <span class="s1">&#39;Exposure&#39;</span><span class="p">]</span>
<span class="n">pred_probs</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;Risk </span><span class="si">{</span><span class="n">c</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">pred_probs</span><span class="o">.</span><span class="n">columns</span><span class="p">]</span>

<span class="n">pred_probs</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="a-possible-interpretation">
<h2>A possible interpretation<a class="headerlink" href="#a-possible-interpretation" title="Link to this heading">#</a></h2>
<p>Respondents who were exposed to a flood WWA were less likely to report no risk (10% ‚Üí 8%) or low risk (32% ‚Üí 28%), and more likely to report higher levels of risk perception, particularly at the ‚ÄúHigh‚Äù (15% ‚Üí 18%) and ‚ÄúExtreme‚Äù (9% ‚Üí 11%) categories. While the percentage point changes may look modest, they indicate a clear upward shift in perceived flood risk among those who received WWAs.  In other words, I think it is possible to say that exposure to a flood warning nudged people away from saying ‚Äòno risk‚Äô and toward saying ‚Äòhigh or extreme risk.  However, with only 3,000 responses, I probably wouldn‚Äôt.  But, as the academics say, this requires further study. üòâ</p>
<p>Now let‚Äôs take a look at a visualization of these results.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#let&#39;s see HOW the probability distribution shift</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">pred_probs</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;bar&#39;</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Predicted Flood Risk Perception by WWA Exposure&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Probability&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Perceived Flood Risk Level&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;WWA Exposure&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="wrapping-up">
<h2>Wrapping Up<a class="headerlink" href="#wrapping-up" title="Link to this heading">#</a></h2>
<p>In this tutorial, we explored how to bring together <strong>social survey data</strong> and <strong>weather warning data</strong> to better understand how hazard information might influence perceptions of risk. Using the Jupyter Notebook environment, you saw how to:</p>
<ul class="simple">
<li><p><strong>Work with APIs</strong> to search for, access, and download data programmatically</p></li>
<li><p>Organize and explore datasets interactively using python libraries like <strong>pandas</strong> and <strong>requests</strong>.</p></li>
<li><p>Merge survey data with external data from the <strong>Iowa Environmental Mesonet</strong></p></li>
<li><p>Apply <strong>geospatial tools</strong> to handle location-based data</p></li>
<li><p>Create clear, reproducible <strong>visualizations</strong> and <strong>statistical analyses</strong> directly alongside your analysis</p></li>
<li><p>Document your process in a way that combines code, results, and explanation all in one place</p></li>
</ul>
<p>With this walkthrough, you‚Äôve seen how Jupyter can serve as both a <strong>research lab and a communication tool</strong>‚Äîa space where you can work with data, analyze the data, visualize the data and results, and explain what you found.</p>
<section id="moving-forward">
<h3>Moving Forward<a class="headerlink" href="#moving-forward" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Try adapting this workflow to other survey topics (e.g., heat, drought, tornado risk)</p></li>
<li><p>Explore additional APIs to enrich your analysis with different kinds of data</p></li>
<li><p>Use Jupyter notebooks to build <strong>reproducible reports</strong>, where readers can see not just your conclusions but also the steps you took to get there</p></li>
<li><p>Share your notebooks with collaborators as a way to make your analysis <strong>transparent and interactive</strong></p></li>
</ul>
<p>Ultimately, the key takeaway is that with just a few tools‚Äî<strong>APIs, pandas, geospatial libraries, and Jupyter notebooks</strong>‚Äîyou can connect diverse datasets, analyze them in context, and tell meaningful data stories about risk and society.</p>
<hr class="docutils" />
<p><strong>Thank you for following along!</strong><br />
We encourage you to take this workflow and apply it to your own research questions about weather, risk, and society‚Äîthe more you explore, the more insights you‚Äôll uncover.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./notebooks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../tutorials/forum2-overview.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Forum 2 - From Metadata to Insights</p>
      </div>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#goals-of-the-notebook">Goals of the notebook:</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-steps-we-will-follow">The Steps We Will Follow</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stop-think-about-your-own-data">Stop!  Think About Your Own Data</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#respond-in-the-chat"><strong>&gt;&gt;Respond in the chat&lt;&lt;</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#before-we-get-started-workplace-setup-imports">Before We Get Started - Workplace Setup (Imports)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1-use-an-api-to-explore-a-repository-view-metadata-and-download-data">Step 1: Use an API to explore a repository, view metadata, and download data</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simple-search-for-10-results">Simple search for 10 results</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transform-the-json-results">Transform the JSON results</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#search-for-more-than-10-results">Search for more than 10 results</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#subsetting-our-results">Subsetting Our Results</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1a-get-dataset-metadata-and-files">Step 1a: Get Dataset Metadata and Files</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#getting-metadata-for-a-single-dataset">Getting metadata for a single dataset</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#file-level-metadata">File level metadata</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#full-dataset-metadata">Full dataset metadata</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1b-download-a-file">Step 1b: Download a File</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#examine-the-dataset">Examine the dataset</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#variable-names">Variable names</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id1"><strong>&gt;&gt;Respond in the chat&lt;&lt;</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#unfortunately-nws-region-only-has-four-regions-nonetheless-it-might-be-useful-for-a-different-research-question">Unfortunately, ‚Äúnws_region‚Äù only has four regions.  Nonetheless, it might be useful for a different research question.</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-2-use-an-api-to-download-weather-data">Step 2: Use an API to download weather data</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#iowa-mesonet-api-do-not-run-at-this-time">Iowa Mesonet API - DO NOT RUN AT THIS TIME</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-3-joining-the-survey-data-with-weather-alerts">Step 3 - Joining the Survey Data with Weather Alerts</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#if-you-ran-the-api-call-in-step-2-you-should-skip-the-next-two-cells">If you ran the API call in Step 2, you should skip the next two cells.</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#if-you-ran-the-api-call-in-step-2-you-can-resume-here">If you ran the API call in Step 2, you can resume here.</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-3a-exporting-the-data-for-use-outside-jupyter">Step 3a: Exporting the Data for Use Outside Jupyter</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-4-exploring-the-combined-dataset">Step 4: Exploring the Combined Dataset</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#step-4a-quick-visualizations">Step 4a: Quick visualizations</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-4b-visualizing-wwwas-by-survey-reponses">Step 4b: Visualizing WWWAs by Survey Reponses</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-4c-quick-statistical-analyses">Step 4C: Quick Statistical Analyses</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#chi-square">1. Chi-Square</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#logistic-regression">2. Logistic Regression</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ordinal-logistic-regression">3. Ordinal Logistic Regression</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-bit-more-involved-did-wwas-really-affect-risk-perception">A Bit More Involved - Did WWAs <em>Really</em> Affect Risk Perception?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-possible-interpretation">A possible interpretation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#wrapping-up">Wrapping Up</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#moving-forward">Moving Forward</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Jupyter Book community
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      ¬© Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>